<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="YT7QzoP0CGYZziDQuLr2aOTGGmpgioKi3izg5T1vBPs" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="yongfeiuall,唐胡璐,软件测试,自动化测试,性能测试,Software Testing,QTP,Selenium,Performance Testing" />





  <link rel="alternate" href="/atom.xml" title="YONGFEIUALL" type="application/atom+xml" />






<meta name="description" content="i just wanna live while i am alive">
<meta property="og:type" content="website">
<meta property="og:title" content="YONGFEIUALL">
<meta property="og:url" content="http://izheyi.com/page/4/index.html">
<meta property="og:site_name" content="YONGFEIUALL">
<meta property="og:description" content="i just wanna live while i am alive">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="YONGFEIUALL">
<meta name="twitter:description" content="i just wanna live while i am alive">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://izheyi.com/page/4/"/>





  <title>YONGFEIUALL</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?964433a58390bc50ac82f1418eb8dc8e";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">YONGFEIUALL</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">izheyi.com</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'fZPEsEHs3tafejXBDpZs','2.0.0');
</script>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/06/25/K8s-数据存储/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/25/K8s-数据存储/" itemprop="url">K8s：数据存储</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-06-25T13:51:00+08:00">
                2021-06-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/25/K8s-数据存储/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/06/25/K8s-数据存储/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在前面已经提到，容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。为了持久化保存容器的数据，kubernetes引入了Volume的概念。</p>
<p>Volume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。</p>
<h4 id="基本存储"><a href="#基本存储" class="headerlink" title="基本存储"></a>基本存储</h4><h6 id="EmptyDir"><a href="#EmptyDir" class="headerlink" title="EmptyDir"></a>EmptyDir</h6><p>一种临时存储，pod创建的时候会在node节点上为容器申请一个临时的目录，跟随容器的生命周期，如容器删除，emptyDir定义的临时存储空间也会随之删除，容器发生意外crash则不受影响，同时如果容器发生了迁移，其上的数据也会丢失，emptyDir一般用于测试，或者缓存场景。<code>注意：一个容器崩溃了不会导致数据的丢失，因为容器的崩溃并不移除pod.</code></p>
<p><img src="/images/k8s/emptydir.jpg" alt=""></p>
<p>资源文件：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1&#10;kind: Pod&#10;metadata:&#10;  name: volume-emptydir&#10;  namespace: dev&#10;spec:&#10;  containers:&#10;  - name: nginx&#10;    image: nginx:1.17.1&#10;    ports:&#10;    - containerPort: 80&#10;    volumeMounts:  # &#23558;logs-volume&#25346;&#22312;&#21040;nginx&#23481;&#22120;&#20013;&#65292;&#23545;&#24212;&#30340;&#30446;&#24405;&#20026; /var/log/nginx&#10;    - name: logs-volume&#10;      mountPath: /var/log/nginx&#10;  - name: busybox&#10;    image: busybox:1.30&#10;    command: [&#34;/bin/sh&#34;,&#34;-c&#34;,&#34;tail -f /logs/access.log&#34;] # &#21021;&#22987;&#21629;&#20196;&#65292;&#21160;&#24577;&#35835;&#21462;&#25351;&#23450;&#25991;&#20214;&#20013;&#20869;&#23481;&#10;    volumeMounts:  # &#23558;logs-volume &#25346;&#22312;&#21040;busybox&#23481;&#22120;&#20013;&#65292;&#23545;&#24212;&#30340;&#30446;&#24405;&#20026; /logs&#10;    - name: logs-volume&#10;      mountPath: /logs&#10;  volumes: # &#22768;&#26126;volume&#65292; name&#20026;logs-volume&#65292;&#31867;&#22411;&#20026;emptyDir&#10;  - name: logs-volume&#10;    emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">关于type的值的一点说明：</span><br><span class="line">    DirectoryOrCreate 目录存在就使用，不存在就先创建后使用</span><br><span class="line">    <span class="keyword">Directory</span>   目录必须存在</span><br><span class="line">    FileOrCreate  文件存在就使用，不存在就先创建后使用</span><br><span class="line">    <span class="keyword">File</span> 文件必须存在 </span><br><span class="line">    <span class="keyword">Socket</span>  unix套接字必须存在</span><br><span class="line">    CharDevice  字符设备必须存在</span><br><span class="line">    BlockDevice 块设备必须存在</span><br></pre></td></tr></table></figure>
<h6 id="HostPath"><a href="#HostPath" class="headerlink" title="HostPath"></a>HostPath</h6><p>HostPath就是将Node主机中一个实际目录挂在到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依据可以存在于Node主机上。</p>
<p><img src="/images/k8s/hostpath.jpg" alt=""></p>
<h6 id="NFS"><a href="#NFS" class="headerlink" title="NFS"></a>NFS</h6><p>NFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。</p>
<p><img src="/images/k8s/nfs.jpg" alt=""></p>
<h4 id="PV与PVC"><a href="#PV与PVC" class="headerlink" title="PV与PVC"></a>PV与PVC</h4><ul>
<li>PV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。</li>
<li>PVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。</li>
</ul>
<h6 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h6><p>PV是存储资源的抽象，下面是资源清单文件:</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1  </span><br><span class="line"><span class="attribute">kind</span>: PersistentVolume</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: pv2</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">nfs</span>: # 存储类型，与底层真正存储对应</span><br><span class="line">  <span class="attribute">capacity</span>:  # 存储能力，目前只支持存储空间的设置</span><br><span class="line">    <span class="attribute">storage</span>: <span class="number">2</span>Gi</span><br><span class="line">  <span class="attribute">accessModes</span>:  # 访问模式</span><br><span class="line">  <span class="attribute">storageClassName</span>: # 存储类别</span><br><span class="line">  <span class="attribute">persistentVolumeReclaimPolicy</span>: # 回收策略</span><br></pre></td></tr></table></figure>
<p>PV 的关键配置参数说明：</p>
<ul>
<li><p><strong>存储类型</strong></p>
<p>底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异</p>
</li>
<li><p><strong>存储能力（capacity）</strong></p>
<p>目前只支持存储空间的设置( storage=1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置</p>
</li>
<li><p><strong>访问模式（accessModes）</strong></p>
<p>用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：</p>
<ul>
<li>ReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载</li>
<li>ReadOnlyMany（ROX）： 只读权限，可以被多个节点挂载</li>
<li>ReadWriteMany（RWX）：读写权限，可以被多个节点挂载</li>
</ul>
</li>
<li><p><strong>回收策略（persistentVolumeReclaimPolicy）</strong></p>
<p>当PV不再被使用了之后，对其的处理方式。目前支持三种策略：</p>
<ul>
<li>Retain （保留） 保留数据，需要管理员手工清理数据</li>
<li>Recycle（回收） 清除 PV 中的数据，效果相当于执行 rm -rf /thevolume/*</li>
<li>Delete （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务</li>
</ul>
</li>
<li><p><strong>存储类别</strong></p>
<p>PV可以通过storageClassName参数指定一个存储类别</p>
<ul>
<li>具有特定类别的PV只能与请求了该类别的PVC进行绑定</li>
<li>未设定类别的PV则只能与不请求任何类别的PVC进行绑定</li>
</ul>
</li>
<li><p><strong>状态（status）</strong></p>
<p>一个 PV 的生命周期中，可能会处于4中不同的阶段：</p>
<ul>
<li>Available（可用）： 表示可用状态，还未被任何 PVC 绑定</li>
<li>Bound（已绑定）： 表示 PV 已经被 PVC 绑定</li>
<li>Released（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明</li>
<li>Failed（失败）： 表示该 PV 的自动回收失败</li>
</ul>
</li>
</ul>
<h6 id="PVC"><a href="#PVC" class="headerlink" title="PVC"></a>PVC</h6><p>PVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。下面是资源清单文件:</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: PersistentVolumeClaim</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: pvc</span><br><span class="line">  <span class="attribute">namespace</span>: dev</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">accessModes</span>: # 访问模式</span><br><span class="line">  <span class="attribute">selector</span>: # 采用标签对PV选择</span><br><span class="line">  <span class="attribute">storageClassName</span>: # 存储类别</span><br><span class="line">  <span class="attribute">resources</span>: # 请求空间</span><br><span class="line">    <span class="attribute">requests</span>:</span><br><span class="line">      <span class="attribute">storage</span>: <span class="number">5</span>Gi</span><br></pre></td></tr></table></figure>
<p>PVC 的关键配置参数说明：</p>
<ul>
<li><p><strong>访问模式（accessModes）</strong></p>
<p>用于描述用户应用对存储资源的访问权限</p>
</li>
<li><p><strong>选择条件（selector）</strong></p>
<p>通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选</p>
</li>
<li><p><strong>存储类别（storageClassName）</strong></p>
<p>PVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出</p>
</li>
<li><p><strong>资源请求（Resources ）</strong></p>
<p>描述对存储资源的请求</p>
</li>
</ul>
<h6 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h6><p>PV和PVC之间的相互作用遵循这个生命周期:<code>Provisioning ——-&gt; Binding ——–&gt;Using——&gt;Releasing——&gt;Recycling</code></p>
<ul>
<li><strong>资源供应</strong>：管理员手动创建底层存储和PV</li>
<li><strong>资源绑定</strong>：用户创建PVC，k8s负责根据PVC的声明去寻找PV，并绑定</li>
<li><strong>资源使用</strong>：用户可在pod中像volume一样使用pvc</li>
<li><strong>资源释放</strong>：用户删除pvc来释放pv</li>
<li><strong>资源回收</strong>：k8s根据pv设置的回收策略进行资源的回收</li>
</ul>
<h6 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h6><p>k8s使用NFS共享存储有两种方式：</p>
<p>1.手动方式静态创建所需要的PV和PVC。<br>2.通过创建PVC动态地创建对应PV，无需手动创建PV。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/06/23/K8s-Ingress/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/23/K8s-Ingress/" itemprop="url">K8s：Ingress</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-06-23T10:57:24+08:00">
                2021-06-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/23/K8s-Ingress/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/06/23/K8s-Ingress/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>k8s 对外暴露服务（service）主要有两种方式：NotePort, LoadBalance， 此外externalIPs也可以使各类service对外提供服务，但是当集群服务很多的时候，NodePort方式最大的缺点是会占用很多集群机器的端口；LB方式最大的缺点则是每个service一个LB又有点浪费和麻烦，并且需要k8s之外的支持； 而ingress则只需要一个NodePort或者一个LB就可以满足所有service对外服务的需求。</p>
<p>举个例子，现在集群有api、文件存储、前端3个service，可以通过一个ingress对象来实现图中的请求转发：</p>
<p><img src="/images/k8s/ingress.jpg" alt=""></p>
<p>实际上，Ingress相当于一个7层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解成在<strong>Ingress里建立诸多映射规则，Ingress Controller通过监听这些配置规则并转化成Nginx的反向代理配置 , 然后对外部提供服务</strong>。在这里有两个核心概念：</p>
<ul>
<li>ingress：kubernetes中的一个对象，作用是定义请求如何转发到service的规则</li>
<li>ingress controller：具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发，实现方式有很多，比如Nginx, Contour, Haproxy等等</li>
</ul>
<p>Ingress（以Nginx为例）的工作原理如下：</p>
<ol>
<li><p>用户编写Ingress规则，说明哪个域名对应kubernetes集群中的哪个Service</p>
</li>
<li><p>Ingress控制器动态感知Ingress服务规则的变化，然后生成一段对应的Nginx反向代理配置</p>
</li>
<li><p>Ingress控制器会将生成的Nginx配置写入到一个运行着的Nginx服务中，并动态更新</p>
</li>
<li><p>到此为止，其实真正在工作的就是一个Nginx了，内部配置了用户定义的请求转发规则</p>
<p><img src="/images/k8s/nginx.jpg" alt=""></p>
</li>
</ol>
<h4 id="Ingress的使用"><a href="#Ingress的使用" class="headerlink" title="Ingress的使用"></a>Ingress的使用</h4><h6 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h6><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# mkdir ingress&#10;[root@master ~]# cd ingress&#10;&#10;[root@master ingress]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml&#10;--2021-10-19 11:11:40--  https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml&#10;&#27491;&#22312;&#35299;&#26512;&#20027;&#26426; raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...&#10;&#27491;&#22312;&#36830;&#25509; raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... &#24050;&#36830;&#25509;&#12290;&#10;&#24050;&#21457;&#20986; HTTP &#35831;&#27714;&#65292;&#27491;&#22312;&#31561;&#24453;&#22238;&#24212;... 200 OK&#10;&#38271;&#24230;&#65306;6635 (6.5K) [text/plain]&#10;&#27491;&#22312;&#20445;&#23384;&#33267;: &#8220;mandatory.yaml&#8221;&#10;&#10;[root@master ingress]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml&#10;--2021-10-19 11:11:55--  https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml&#10;&#27491;&#22312;&#35299;&#26512;&#20027;&#26426; raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...&#10;&#27491;&#22312;&#36830;&#25509; raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... &#24050;&#36830;&#25509;&#12290;&#10;&#24050;&#21457;&#20986; HTTP &#35831;&#27714;&#65292;&#27491;&#22312;&#31561;&#24453;&#22238;&#24212;... 200 OK&#10;&#38271;&#24230;&#65306;471 [text/plain]&#10;&#27491;&#22312;&#20445;&#23384;&#33267;: &#8220;service-nodeport.yaml&#8221;&#10;&#10;[root@master ingress]# ls&#10;mandatory.yaml  service-nodeport.yaml&#10;[root@master ingress]# kubectl apply -f ./&#10;namespace/ingress-nginx created&#10;configmap/nginx-configuration created&#10;configmap/tcp-services created&#10;configmap/udp-services created&#10;serviceaccount/nginx-ingress-serviceaccount created&#10;clusterrole.rbac.authorization.k8s.io/nginx-ingress-clusterrole created&#10;role.rbac.authorization.k8s.io/nginx-ingress-role created&#10;rolebinding.rbac.authorization.k8s.io/nginx-ingress-role-nisa-binding created&#10;clusterrolebinding.rbac.authorization.k8s.io/nginx-ingress-clusterrole-nisa-binding created&#10;deployment.apps/nginx-ingress-controller created&#10;limitrange/ingress-nginx created&#10;service/ingress-nginx created&#10;&#10;[root@master ingress]# kubectl get pod -n ingress-nginx&#10;NAME                                        READY   STATUS              RESTARTS   AGE&#10;nginx-ingress-controller-7f74f657bd-q5zwf   0/1     Running              0          16s&#10;[root@master ingress]# kubectl get pod,svc -n ingress-nginx&#10;NAME                                            READY   STATUS              RESTARTS   AGE&#10;pod/nginx-ingress-controller-7f74f657bd-q5zwf   0/1     ContainerCreating   0          31s&#10;&#10;NAME                    TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE&#10;service/ingress-nginx   NodePort   10.106.103.131   &#60;none&#62;        80:32635/TCP,443:31777/TCP   31s</span><br></pre></td></tr></table></figure>
<h6 id="Service和Pod"><a href="#Service和Pod" class="headerlink" title="Service和Pod"></a>Service和Pod</h6><p>创建tomcat-nginx.yaml</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: apps/v1</span><br><span class="line"><span class="attribute">kind</span>: Deployment</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: nginx-deployment</span><br><span class="line">  <span class="attribute">namespace</span>: dev</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">replicas</span>: <span class="number">3</span></span><br><span class="line">  <span class="attribute">selector</span>:</span><br><span class="line">    <span class="attribute">matchLabels</span>:</span><br><span class="line">      <span class="attribute">app</span>: nginx-pod</span><br><span class="line">  <span class="attribute">template</span>:</span><br><span class="line">    <span class="attribute">metadata</span>:</span><br><span class="line">      <span class="attribute">labels</span>:</span><br><span class="line">        <span class="attribute">app</span>: nginx-pod</span><br><span class="line">    <span class="attribute">spec</span>:</span><br><span class="line">      <span class="attribute">containers</span>:</span><br><span class="line">      - <span class="attribute">name</span>: nginx</span><br><span class="line">        <span class="attribute">image</span>: <span class="attribute">nginx</span>:<span class="number">1.17</span>.<span class="number">1</span></span><br><span class="line">        <span class="attribute">ports</span>:</span><br><span class="line">        - <span class="attribute">containerPort</span>: <span class="number">80</span></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="attribute">apiVersion</span>: apps/v1</span><br><span class="line"><span class="attribute">kind</span>: Deployment</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: tomcat-deployment</span><br><span class="line">  <span class="attribute">namespace</span>: dev</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">replicas</span>: <span class="number">3</span></span><br><span class="line">  <span class="attribute">selector</span>:</span><br><span class="line">    <span class="attribute">matchLabels</span>:</span><br><span class="line">      <span class="attribute">app</span>: tomcat-pod</span><br><span class="line">  <span class="attribute">template</span>:</span><br><span class="line">    <span class="attribute">metadata</span>:</span><br><span class="line">      <span class="attribute">labels</span>:</span><br><span class="line">        <span class="attribute">app</span>: tomcat-pod</span><br><span class="line">    <span class="attribute">spec</span>:</span><br><span class="line">      <span class="attribute">containers</span>:</span><br><span class="line">      - <span class="attribute">name</span>: tomcat</span><br><span class="line">        <span class="attribute">image</span>: <span class="attribute">tomcat</span>:<span class="number">8.5</span>-jre10-slim</span><br><span class="line">        <span class="attribute">ports</span>:</span><br><span class="line">        - <span class="attribute">containerPort</span>: <span class="number">8080</span></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Service</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: nginx-service</span><br><span class="line">  <span class="attribute">namespace</span>: dev</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">selector</span>:</span><br><span class="line">    <span class="attribute">app</span>: nginx-pod</span><br><span class="line">  <span class="attribute">clusterIP</span>: None</span><br><span class="line">  <span class="attribute">type</span>: ClusterIP</span><br><span class="line">  <span class="attribute">ports</span>:</span><br><span class="line">  - <span class="attribute">port</span>: <span class="number">80</span></span><br><span class="line">    <span class="attribute">targetPort</span>: <span class="number">80</span></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Service</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: tomcat-service</span><br><span class="line">  <span class="attribute">namespace</span>: dev</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">selector</span>:</span><br><span class="line">    <span class="attribute">app</span>: tomcat-pod</span><br><span class="line">  <span class="attribute">clusterIP</span>: None</span><br><span class="line">  <span class="attribute">type</span>: ClusterIP</span><br><span class="line">  <span class="attribute">ports</span>:</span><br><span class="line">  - <span class="attribute">port</span>: <span class="number">8080</span></span><br><span class="line">    <span class="attribute">targetPort</span>: <span class="number">8080</span></span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ingress]# kubectl create -f tomcat-nginx.yaml&#10;deployment.apps/nginx-deployment created&#10;deployment.apps/tomcat-deployment created&#10;service/nginx-service created&#10;service/tomcat-service created&#10;&#10;[root@master ingress]# kubectl get pod,svc -n dev&#10;NAME                                     READY   STATUS    RESTARTS   AGE&#10;pod/nginx-deployment-6696798b78-4z9h9    1/1     Running   0          3m45s&#10;pod/nginx-deployment-6696798b78-n2ff8    1/1     Running   0          3m45s&#10;pod/nginx-deployment-6696798b78-xbnjh    1/1     Running   0          3m45s&#10;pod/tomcat-deployment-58467d5474-4t275   1/1     Running   0          3m45s&#10;pod/tomcat-deployment-58467d5474-c6cst   1/1     Running   0          3m45s&#10;pod/tomcat-deployment-58467d5474-mrpww   1/1     Running   0          3m45s&#10;&#10;NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE&#10;service/nginx-service    ClusterIP   None             &#60;none&#62;        80/TCP         3m45s&#10;service/tomcat-service   ClusterIP   None             &#60;none&#62;        8080/TCP       3m45s</span><br></pre></td></tr></table></figure>
<h6 id="HTTP代理"><a href="#HTTP代理" class="headerlink" title="HTTP代理"></a>HTTP代理</h6><p>创建ingress-http.yaml</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1&#10;kind: Ingress&#10;metadata:&#10;  name: ingress-http&#10;  namespace: dev&#10;spec:&#10;  rules:&#10;  - host: nginx.izheyi.com&#10;    http:&#10;      paths:&#10;      - path: /&#10;        backend:&#10;          serviceName: nginx-service&#10;          servicePort: 80&#10;  - host: tomcat.izheyi.com&#10;    http:&#10;      paths:&#10;      - path: /&#10;        backend:&#10;          serviceName: tomcat-service&#10;          servicePort: 8080</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ingress]# kubectl create -f ingress-http.yaml &#10;ingress.extensions/ingress-http created&#10;&#10;[root@master ingress]# kubectl get ing ingress-http -n dev&#10;NAME           HOSTS                                ADDRESS   PORTS   AGE&#10;ingress-http   nginx.izheyi.com,tomcat.izheyi.com             80      5s&#10;&#10;[root@master ingress]# kubectl describe ing ingress-http  -n dev&#10;Name:             ingress-http&#10;Namespace:        dev&#10;Address:          &#10;Default backend:  default-http-backend:80 (&#60;none&#62;)&#10;Rules:&#10;  Host               Path  Backends&#10;  ----               ----  --------&#10;  nginx.izheyi.com   &#10;                     /   nginx-service:80 (10.244.1.20:80,10.244.1.21:80,10.244.2.26:80)&#10;  tomcat.izheyi.com  &#10;                     /   tomcat-service:8080 (10.244.1.22:8080,10.244.2.24:8080,10.244.2.25:8080)&#10;Annotations:&#10;Events:&#10;  Type    Reason  Age   From                      Message&#10;  ----    ------  ----  ----                      -------&#10;  Normal  CREATE  27s   nginx-ingress-controller  Ingress dev/ingress-http</span><br></pre></td></tr></table></figure>
<p>增加Hosts</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.36.10 nginx.izheyi.com&#10;192.168.36.10 tomcat.izheyi.com</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get svc -n ingress-nginx&#10;NAME            TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE&#10;ingress-nginx   NodePort   10.106.103.131   &#60;none&#62;        80:32635/TCP,443:31777/TCP   124m</span><br></pre></td></tr></table></figure>
<p><img src="/images/k8s/nginx_tomcat.jpg" alt=""></p>
<h6 id="HTTPS代理"><a href="#HTTPS代理" class="headerlink" title="HTTPS代理"></a>HTTPS代理</h6><ol>
<li><p>创建证书</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#29983;&#25104;&#35777;&#20070;&#10;[root@master ~]# openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &#34;/C=CN/ST=BJ/L=BJ/O=nginx/CN=izhey.com&#34;&#10;Generating a 2048 bit RSA private key&#10;..........................................................+++&#10;..................................................................................................................................+++&#10;writing new private key to &#39;tls.key&#39;&#10;-----&#10;&#10;# &#21019;&#24314;&#23494;&#38053;&#10;[root@master ~]# kubectl create secret tls tls-secret --key tls.key --cert tls.crt&#10;secret/tls-secret created</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>创建ingress-https.yaml</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1&#10;kind: Ingress&#10;metadata:&#10;  name: ingress-https&#10;  namespace: dev&#10;spec:&#10;  tls:&#10;    - hosts:&#10;      - nginx.itheima.com&#10;      - tomcat.itheima.com&#10;      secretName: tls-secret # &#25351;&#23450;&#31192;&#38053;&#10;  rules:&#10;  - host: nginx.izheyi.com&#10;    http:&#10;      paths:&#10;      - path: /&#10;        backend:&#10;          serviceName: nginx-service&#10;          servicePort: 80&#10;  - host: tomcat.izheyi.com&#10;    http:&#10;      paths:&#10;      - path: /&#10;        backend:&#10;          serviceName: tomcat-service&#10;          servicePort: 8080</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl create -f ingress-https.yaml&#10;ingress.extensions/ingress-https created&#10;[root@master ~]# kubectl get ing ingress-https -n dev&#10;NAME            HOSTS                                ADDRESS   PORTS     AGE&#10;ingress-https   nginx.izheyi.com,tomcat.izheyi.com             80, 443   11s&#10;[root@master ~]# kubectl describe ing ingress-https -n dev&#10;Name:             ingress-https&#10;Namespace:        dev&#10;Address:          10.106.103.131&#10;Default backend:  default-http-backend:80 (&#60;none&#62;)&#10;TLS:&#10;  tls-secret terminates nginx.itheima.com,tomcat.itheima.com&#10;Rules:&#10;  Host               Path  Backends&#10;  ----               ----  --------&#10;  nginx.izheyi.com   &#10;                     /   nginx-service:80 (10.244.1.20:80,10.244.1.21:80,10.244.2.26:80)&#10;  tomcat.izheyi.com  &#10;                     /   tomcat-service:8080 (10.244.1.22:8080,10.244.2.24:8080,10.244.2.25:8080)&#10;Annotations:&#10;Events:&#10;  Type    Reason  Age   From                      Message&#10;  ----    ------  ----  ----                      -------&#10;  Normal  CREATE  25s   nginx-ingress-controller  Ingress dev/ingress-https&#10;  Normal  UPDATE  3s    nginx-ingress-controller  Ingress dev/ingress-https</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get svc -n ingress-nginx&#10;NAME            TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE&#10;ingress-nginx   NodePort   10.106.103.131   &#60;none&#62;        80:32635/TCP,443:31777/TCP   148m</span><br></pre></td></tr></table></figure>
</li>
<li><p>用<code>https://</code>即可访问</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://nginx.izheyi.com:31777/&#10;&#10;https://tomcat.izheyi.com:31777/</span><br></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/06/19/K8s-Service/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/19/K8s-Service/" itemprop="url">K8s：Service</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-06-19T10:37:06+08:00">
                2021-06-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/19/K8s-Service/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/06/19/K8s-Service/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在k8stes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。</p>
<p>为了解决这个问题，k8s提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。</p>
<h4 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h4><p>Service在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后<strong>它会将最新的Service信息转换成对应的访问规则</strong>。</p>
<p>有三种代理模式</p>
<p>userspace和iptables不做解读，最常用的是ipvs模式。</p>
<p><img src="/images/k8s/ipvs.jpg" alt=""></p>
<p>Client Pod请求到达内核空间时，根据ipvs规则直接分发到各Pod上。kube-proxy会监视Kubernetes Service对象和Endpoints，调用netlink接口以相应的创建ipvs规则并定期与Kubernetes Service对象和Endpoints对象同步ipvs规则，以确保ipvs状态与期望一致。访问服务时，流量将被重定向到其中一个后端Pod。</p>
<p>此外，ipvs为负载均衡算法提供了更多选项，例如：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rr：轮询调度</span><br><span class="line"><span class="keyword">lc</span>：最小连接数</span><br><span class="line">dh：目标哈希</span><br><span class="line"><span class="keyword">sh</span>：源哈希</span><br><span class="line">sed：最短期望延迟</span><br><span class="line">nq：不排队调度</span><br></pre></td></tr></table></figure>
<h4 id="Service类型"><a href="#Service类型" class="headerlink" title="Service类型"></a>Service类型</h4><p>Service的资源清单文件：</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="label">kind:</span> Service  <span class="preprocessor"># 资源类型</span></span><br><span class="line"><span class="label">apiVersion:</span> v1  <span class="preprocessor"># 资源版本</span></span><br><span class="line"><span class="label">metadata:</span> <span class="preprocessor"># 元数据</span></span><br><span class="line">  name: service <span class="preprocessor"># 资源名称</span></span><br><span class="line">  namespace: dev <span class="preprocessor"># 命名空间</span></span><br><span class="line"><span class="label">spec:</span> <span class="preprocessor"># 描述</span></span><br><span class="line">  selector: <span class="preprocessor"># 标签选择器，用于确定当前service代理哪些pod</span></span><br><span class="line">    app: nginx</span><br><span class="line">  type: <span class="preprocessor"># Service类型，指定service的访问方式</span></span><br><span class="line">  clusterIP:  <span class="preprocessor"># 虚拟服务的ip地址</span></span><br><span class="line">  sessionAffinity: <span class="preprocessor"># session亲和性，支持ClientIP、None两个选项</span></span><br><span class="line">  ports: <span class="preprocessor"># 端口信息</span></span><br><span class="line">    - protocol: TCP </span><br><span class="line">      port: <span class="number">3017</span>  <span class="preprocessor"># service端口</span></span><br><span class="line">      targetPort: <span class="number">5003</span> <span class="preprocessor"># pod端口</span></span><br><span class="line">      nodePort: <span class="number">31122</span> <span class="preprocessor"># 主机端口</span></span><br></pre></td></tr></table></figure>
<ul>
<li>ClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问</li>
<li>NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务</li>
<li>LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持</li>
<li>ExternalName： 把集群外部的服务引入集群内部，直接使用</li>
</ul>
<h4 id="Endpoints-amp-Headless"><a href="#Endpoints-amp-Headless" class="headerlink" title="Endpoints &amp; Headless"></a>Endpoints &amp; Headless</h4><ul>
<li><p>Endpoints</p>
<p>Endpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。</p>
<p>一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，<strong>Endpoints是实现实际服务的端点集合</strong>。换句话说，service和pod之间的联系是通过endpoints实现的。</p>
<p><img src="/images/k8s/endpoint.jpg" alt=""></p>
</li>
<li><p>Headless</p>
<p>在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLiness Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/06/10/K8s-Pod控制器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/10/K8s-Pod控制器/" itemprop="url">K8s：Pod控制器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-06-10T09:40:55+08:00">
                2021-06-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/10/K8s-Pod控制器/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/06/10/K8s-Pod控制器/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Pod控制器是用于实现管理pod的中间层，确保pod资源符合预期的状态，pod的资源出现故障时，会尝试进行重启，当根据重启策略无效，则会重新新建pod的资源。分为以下几类：</p>
<ul>
<li>ReplicaSet：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级</li>
<li>Deployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本</li>
<li>Horizontal Pod Autoscaler：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷</li>
<li>DaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务</li>
<li>Job：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务</li>
<li>Cronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行</li>
<li>StatefulSet：管理有状态应用，作为 Controller 为 Pod 提供唯一的标识。它可以保证部署和 scale 的顺序，<code>StatefulSet是为了解决有状态服务的问题</code>（对应Deployments和ReplicaSets是为无状态服务而设计）。</li>
</ul>
<h4 id="ReplicaSet"><a href="#ReplicaSet" class="headerlink" title="ReplicaSet"></a>ReplicaSet</h4><p>ReplicaSet的主要作用是<strong>保证一定数量的pod正常运行</strong>，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。</p>
<p>ReplicaSet的资源清单文件：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1 <span class="preprocessor"># 版本号</span></span><br><span class="line">kind: ReplicaSet <span class="preprocessor"># 类型       </span></span><br><span class="line">metadata: <span class="preprocessor"># 元数据</span></span><br><span class="line">  name: <span class="preprocessor"># rs名称 </span></span><br><span class="line">  <span class="keyword">namespace</span>: <span class="preprocessor"># 所属命名空间 </span></span><br><span class="line">  labels: <span class="preprocessor">#标签</span></span><br><span class="line">    controller: rs</span><br><span class="line">spec: <span class="preprocessor"># 详情描述</span></span><br><span class="line">  replicas: <span class="number">3</span> <span class="preprocessor"># 副本数量</span></span><br><span class="line">  selector: <span class="preprocessor"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    matchLabels:      <span class="preprocessor"># Labels匹配规则</span></span><br><span class="line">      app: nginx-pod</span><br><span class="line">    matchExpressions: <span class="preprocessor"># Expressions匹配规则</span></span><br><span class="line">      - &#123;key: app, <span class="keyword">operator</span>: In, values: [nginx-pod]&#125;</span><br><span class="line">  <span class="keyword">template</span>: <span class="preprocessor"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-pod</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:<span class="number">1.17</span><span class="number">.1</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">80</span></span><br></pre></td></tr></table></figure>
<p>需要新了解的配置项就是<code>spec</code>下面几个选项：</p>
<ul>
<li><p>replicas：指定副本数量，其实就是当前rs创建出来的pod的数量，默认为1</p>
</li>
<li><p>selector：选择器，它的作用是建立pod控制器和pod之间的关联关系，采用的Label Selector机制</p>
<p>在pod模板上定义label，在控制器上定义选择器，就可以表明当前控制器能管理哪些pod了</p>
</li>
<li><p>template：模板，就是当前控制器创建pod所使用的模板板</p>
</li>
</ul>
<p>创建pc-replicaset.yaml文件：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1&#10;kind: ReplicaSet   &#10;metadata:&#10;  name: pc-replicaset&#10;  namespace: dev&#10;spec:&#10;  replicas: 3&#10;  selector: &#10;    matchLabels:&#10;      app: nginx-pod&#10;  template:&#10;    metadata:&#10;      labels:&#10;        app: nginx-pod&#10;    spec:&#10;      containers:&#10;      - name: nginx&#10;        image: nginx:1.17.1</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor"># 创建</span></span><br><span class="line">[root@master ~]<span class="preprocessor"># kubectl create -f pc-replicaset.yaml</span></span><br><span class="line">replicaset.apps/pc-replicaset created</span><br><span class="line"></span><br><span class="line"><span class="preprocessor"># 查看rs</span></span><br><span class="line">[root@master ~]<span class="preprocessor"># kubectl get rs pc-replicaset -n dev -o wide</span></span><br><span class="line">NAME          DESIRED   CURRENT READY AGE   CONTAINERS   IMAGES             SELECTOR</span><br><span class="line">pc-replicaset <span class="number">3</span>         <span class="number">3</span>       <span class="number">3</span>     <span class="number">22</span>s   nginx        nginx:<span class="number">1.17</span><span class="number">.1</span>       app=nginx-pod</span><br><span class="line"></span><br><span class="line"><span class="preprocessor"># 查看当前控制器创建出来的pod</span></span><br><span class="line">[root@master ~]<span class="preprocessor"># kubectl get pod -n dev</span></span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-replicaset-<span class="number">6</span>vmvt   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">54</span>s</span><br><span class="line">pc-replicaset-fmb8f   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">54</span>s</span><br><span class="line">pc-replicaset-snrk2   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">54</span>s</span><br></pre></td></tr></table></figure>
<p>两种方式实现扩缩容</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#32534;&#36753;rs&#30340;&#21103;&#26412;&#25968;&#37327;&#65292;&#20462;&#25913;spec:replicas: 6&#21363;&#21487;&#10;[root@master ~]# kubectl edit rs pc-replicaset -n dev&#10;replicaset.apps/pc-replicaset edited&#10;&#10;# &#24403;&#28982;&#20063;&#21487;&#20197;&#30452;&#25509;&#20351;&#29992;&#21629;&#20196;&#23454;&#29616;&#10;# &#20351;&#29992;scale&#21629;&#20196;&#65292; &#21518;&#38754;--replicas=n&#30452;&#25509;&#25351;&#23450;&#30446;&#26631;&#25968;&#37327;&#21363;&#21487;&#10;[root@master ~]# kubectl scale rs pc-replicaset --replicas=2 -n dev&#10;replicaset.apps/pc-replicaset scaled</span><br></pre></td></tr></table></figure>
<h4 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h4><p>这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod</p>
<p><img src="/images/k8s/deployment.jpg" alt=""></p>
<p>在创建一个Deployment时，会自动创建一个ReplicaSet，然后由ReplicaSet去创建POD。在Deployment升级时，旧的ReplicaSet会保留，但pod都会升级到新的ReplicaSet上。</p>
<p>Deployment的资源清单文件：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1 <span class="preprocessor"># 版本号</span></span><br><span class="line">kind: Deployment <span class="preprocessor"># 类型       </span></span><br><span class="line">metadata: <span class="preprocessor"># 元数据</span></span><br><span class="line">  name: <span class="preprocessor"># rs名称 </span></span><br><span class="line">  <span class="keyword">namespace</span>: <span class="preprocessor"># 所属命名空间 </span></span><br><span class="line">  labels: <span class="preprocessor">#标签</span></span><br><span class="line">    controller: deploy</span><br><span class="line">spec: <span class="preprocessor"># 详情描述</span></span><br><span class="line">  replicas: <span class="number">3</span> <span class="preprocessor"># 副本数量</span></span><br><span class="line">  revisionHistoryLimit: <span class="number">3</span> <span class="preprocessor"># 保留历史版本</span></span><br><span class="line">  paused: <span class="literal">false</span> <span class="preprocessor"># 暂停部署，默认是false</span></span><br><span class="line">  progressDeadlineSeconds: <span class="number">600</span> <span class="preprocessor"># 部署超时时间（s），默认是<span class="number">600</span></span></span><br><span class="line">  strategy: <span class="preprocessor"># 策略</span></span><br><span class="line">    type: RollingUpdate <span class="preprocessor"># 滚动更新策略</span></span><br><span class="line">    rollingUpdate: <span class="preprocessor"># 滚动更新</span></span><br><span class="line">      maxSurge: <span class="number">30</span>% <span class="preprocessor"># 最大额外可以存在的副本数，可以为百分比，也可以为整数</span></span><br><span class="line">      maxUnavailable: <span class="number">30</span>% <span class="preprocessor"># 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数</span></span><br><span class="line">  selector: <span class="preprocessor"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    matchLabels:      <span class="preprocessor"># Labels匹配规则</span></span><br><span class="line">      app: nginx-pod</span><br><span class="line">    matchExpressions: <span class="preprocessor"># Expressions匹配规则</span></span><br><span class="line">      - &#123;key: app, <span class="keyword">operator</span>: In, values: [nginx-pod]&#125;</span><br><span class="line">  <span class="keyword">template</span>: <span class="preprocessor"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-pod</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:<span class="number">1.17</span><span class="number">.1</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">80</span></span><br></pre></td></tr></table></figure>
<h6 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h6><p>创建pc-deployment.yaml：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: apps/v1</span><br><span class="line"><span class="attribute">kind</span>: Deployment</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: nginx-deployment</span><br><span class="line">  <span class="attribute">namespace</span>: dev</span><br><span class="line">  <span class="attribute">labels</span>:</span><br><span class="line">    <span class="attribute">app</span>: nginx</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">replicas</span>: <span class="number">3</span></span><br><span class="line">  <span class="attribute">selector</span>:</span><br><span class="line">    <span class="attribute">matchLabels</span>:</span><br><span class="line">      <span class="attribute">app</span>: nginx</span><br><span class="line">  <span class="attribute">template</span>:</span><br><span class="line">    <span class="attribute">metadata</span>:</span><br><span class="line">      <span class="attribute">labels</span>:</span><br><span class="line">        <span class="attribute">app</span>: nginx</span><br><span class="line">    <span class="attribute">spec</span>:</span><br><span class="line">      <span class="attribute">containers</span>:</span><br><span class="line">      - <span class="attribute">name</span>: nginx</span><br><span class="line">        <span class="attribute">image</span>: <span class="attribute">nginx</span>:<span class="number">1.17</span>.<span class="number">1</span></span><br><span class="line">        <span class="attribute">ports</span>:</span><br><span class="line">        - <span class="attribute">containerPort</span>: <span class="number">80</span></span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl create -f pc-deployment.yaml &#10;deployment.apps/nginx-deployment created&#10;[root@master ~]# kubectl get deploy nginx-deployment -n dev&#10;NAME               READY   UP-TO-DATE   AVAILABLE   AGE&#10;nginx-deployment   3/3     3            3           8s&#10;[root@master ~]# kubectl get pod -n dev&#10;NAME                                READY   STATUS             RESTARTS   AGE&#10;nginx-deployment-68ddf649b8-cnf8q   1/1     Running            0          25s&#10;nginx-deployment-68ddf649b8-dtwbc   1/1     Running            0          25s&#10;nginx-deployment-68ddf649b8-xwsqs   1/1     Running            0          26s</span><br></pre></td></tr></table></figure>
<h6 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h6><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#21464;&#26356;&#21103;&#26412;&#25968;&#37327;&#20026;5&#20010;&#10;[root@master ~]# kubectl scale deploy nginx-deployment --replicas=5  -n dev&#10;deployment.apps/nginx-deployment scaled&#10;&#10;#&#26597;&#30475;&#10;[root@master ~]# kubectl get pod -n dev&#10;NAME                                READY   STATUS    RESTARTS   AGE&#10;nginx-deployment-68ddf649b8-bq8n2   1/1     Running   0          5s&#10;nginx-deployment-68ddf649b8-cnf8q   1/1     Running   0          24m&#10;nginx-deployment-68ddf649b8-dtwbc   1/1     Running   0          24m&#10;nginx-deployment-68ddf649b8-sspml   1/1     Running   0          4s&#10;nginx-deployment-68ddf649b8-xwsqs   1/1     Running   0          24m&#10;&#10;# &#30452;&#25509;&#20462;&#25913;yaml&#25991;&#20214;&#65292;&#20462;&#25913;spec:replicas: 4&#21363;&#21487;&#10;[root@master ~]# kubectl edit deploy pc-deployment -n dev&#10;deployment.apps/pc-deployment edited</span><br></pre></td></tr></table></figure>
<h6 id="镜像更新"><a href="#镜像更新" class="headerlink" title="镜像更新"></a>镜像更新</h6><ul>
<li>通过set 命令直接修改image的版本进行升级：<code>kubectl set image deployment/nginx-deployment nginx=nginx:1.17.2</code></li>
<li>使用 <code>kubectl edit deployment nginx-deployment</code> 来修改image的值。</li>
</ul>
<p>deployment支持两种更新策略:<code>重建更新</code>和<code>滚动更新</code>,可以通过<code>strategy</code>指定策略类型,支持两个属性:</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">strategy</span>：指定新的<span class="type">Pod</span>替换旧的<span class="type">Pod</span>的策略， 支持两个属性：</span><br><span class="line">  <span class="typedef"><span class="keyword">type</span>：指定策略类型，支持两种策略</span></span><br><span class="line">    <span class="type">Recreate</span>：在创建出新的<span class="type">Pod</span>之前会先杀掉所有已存在的<span class="type">Pod</span></span><br><span class="line">    <span class="type">RollingUpdate</span>：滚动更新，就是杀死一部分，就启动一部分，在更新过程中，存在两个版本<span class="type">Pod</span></span><br><span class="line">  rollingUpdate：当<span class="typedef"><span class="keyword">type</span>为<span class="type">RollingUpdate</span>时生效，用于为<span class="type">RollingUpdate</span>设置参数，支持两个属性：</span></span><br><span class="line">    maxUnavailable：用来指定在升级过程中不可用<span class="type">Pod</span>的最大数量，默认为<span class="number">25</span>%。</span><br><span class="line">    maxSurge： 用来指定在升级过程中可以超过期望的<span class="type">Pod</span>的最大数量，默认为<span class="number">25</span>%。</span><br></pre></td></tr></table></figure>
<ul>
<li>Recreate这种方式通常不用</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#21464;&#26356;&#38236;&#20687;&#10;[root@master ~]# kubectl set image deployment pc-deployment nginx=nginx:1.17.2 -n dev&#10;deployment.apps/pc-deployment image updated&#10;&#10;# &#35266;&#23519;&#21319;&#32423;&#36807;&#31243;&#10;[root@master ~]#  kubectl get pods -n dev -w&#10;NAME                             READY   STATUS    RESTARTS   AGE&#10;pc-deployment-5d89bdfbf9-65qcw   1/1     Running   0          31s&#10;pc-deployment-5d89bdfbf9-w5nzv   1/1     Running   0          31s&#10;pc-deployment-5d89bdfbf9-xpt7w   1/1     Running   0          31s&#10;&#10;pc-deployment-5d89bdfbf9-xpt7w   1/1     Terminating   0          41s&#10;pc-deployment-5d89bdfbf9-65qcw   1/1     Terminating   0          41s&#10;pc-deployment-5d89bdfbf9-w5nzv   1/1     Terminating   0          41s&#10;&#10;pc-deployment-675d469f8b-grn8z   0/1     Pending       0          0s&#10;pc-deployment-675d469f8b-hbl4v   0/1     Pending       0          0s&#10;pc-deployment-675d469f8b-67nz2   0/1     Pending       0          0s&#10;&#10;pc-deployment-675d469f8b-grn8z   0/1     ContainerCreating   0          0s&#10;pc-deployment-675d469f8b-hbl4v   0/1     ContainerCreating   0          0s&#10;pc-deployment-675d469f8b-67nz2   0/1     ContainerCreating   0          0s&#10;&#10;pc-deployment-675d469f8b-grn8z   1/1     Running             0          1s&#10;pc-deployment-675d469f8b-67nz2   1/1     Running             0          1s&#10;pc-deployment-675d469f8b-hbl4v   1/1     Running             0          2s</span><br></pre></td></tr></table></figure>
<ul>
<li>rollingUpdate</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#21464;&#26356;&#38236;&#20687;&#10;[root@master ~]# kubectl set image deployment pc-deployment nginx=nginx:1.17.3 -n dev &#10;deployment.apps/pc-deployment image updated&#10;&#10;# &#35266;&#23519;&#21319;&#32423;&#36807;&#31243;&#10;[root@master ~]# kubectl get pods -n dev -w&#10;NAME                           READY   STATUS    RESTARTS   AGE&#10;pc-deployment-c848d767-8rbzt   1/1     Running   0          31m&#10;pc-deployment-c848d767-h4p68   1/1     Running   0          31m&#10;pc-deployment-c848d767-hlmz4   1/1     Running   0          31m&#10;pc-deployment-c848d767-rrqcn   1/1     Running   0          31m&#10;&#10;pc-deployment-966bf7f44-226rx   0/1     Pending             0          0s&#10;pc-deployment-966bf7f44-226rx   0/1     ContainerCreating   0          0s&#10;pc-deployment-966bf7f44-226rx   1/1     Running             0          1s&#10;pc-deployment-c848d767-h4p68    0/1     Terminating         0          34m&#10;&#10;pc-deployment-966bf7f44-cnd44   0/1     Pending             0          0s&#10;pc-deployment-966bf7f44-cnd44   0/1     ContainerCreating   0          0s&#10;pc-deployment-966bf7f44-cnd44   1/1     Running             0          2s&#10;pc-deployment-c848d767-hlmz4    0/1     Terminating         0          34m&#10;&#10;pc-deployment-966bf7f44-px48p   0/1     Pending             0          0s&#10;pc-deployment-966bf7f44-px48p   0/1     ContainerCreating   0          0s&#10;pc-deployment-966bf7f44-px48p   1/1     Running             0          0s&#10;pc-deployment-c848d767-8rbzt    0/1     Terminating         0          34m&#10;&#10;pc-deployment-966bf7f44-dkmqp   0/1     Pending             0          0s&#10;pc-deployment-966bf7f44-dkmqp   0/1     ContainerCreating   0          0s&#10;pc-deployment-966bf7f44-dkmqp   1/1     Running             0          2s&#10;pc-deployment-c848d767-rrqcn    0/1     Terminating         0          34m</span><br></pre></td></tr></table></figure>
<h6 id="版本Rollback"><a href="#版本Rollback" class="headerlink" title="版本Rollback"></a>版本Rollback</h6><p>deployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能，创建deployment时要增加–record参数，才能看到revision的变化。</p>
<p>kubectl rollout： 版本升级相关功能，支持下面的选项：</p>
<ul>
<li>status 显示当前升级状态</li>
<li>history 显示 升级历史记录</li>
<li>pause 暂停版本升级过程</li>
<li>resume 继续已经暂停的版本升级过程</li>
<li>restart 重启版本升级过程</li>
<li>undo 回滚到上一级版本（可以使用–to-revision回滚到指定版本）</li>
</ul>
<h4 id="Horizontal-Pod-Autoscaler-HPA"><a href="#Horizontal-Pod-Autoscaler-HPA" class="headerlink" title="Horizontal Pod Autoscaler(HPA)"></a>Horizontal Pod Autoscaler(HPA)</h4><p>HPA可以获取每个Pod利用率，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值，最后实现Pod的数量的调整。</p>
<h6 id="环境部署"><a href="#环境部署" class="headerlink" title="环境部署"></a>环境部署</h6><ol>
<li><p>安装metrics-server</p>
<p>metrics-server可以用来收集集群中的资源使用情况</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#23433;&#35013;git&#10;[root@master ~]# yum install git -y&#10;&#10;# &#33719;&#21462;metrics-server&#10;[root@master ~]# git clone -b v0.3.6 https://github.com/kubernetes-incubator/metrics-server&#10;# &#20462;&#25913;deployment, &#27880;&#24847;&#20462;&#25913;&#30340;&#26159;&#38236;&#20687;&#21644;&#21021;&#22987;&#21270;&#21442;&#25968;&#10;[root@master ~]# cd /root/metrics-server/deploy/1.8+/&#10;[root@master 1.8+]# vim metrics-server-deployment.yaml&#10;metadata:&#10;  name: metrics-server&#10;  namespace: kube-system&#10;  labels:&#10;    k8s-app: metrics-server&#10;spec:&#10;  selector:&#10;    matchLabels:&#10;      k8s-app: metrics-server&#10;  template:&#10;    metadata:&#10;      name: metrics-server&#10;      labels:&#10;        k8s-app: metrics-server&#10;    spec:&#10;      hostNetwork: true&#10;      serviceAccountName: metrics-server&#10;      volumes:&#10;      # mount in tmp so we can safely use from-scratch images and/or read-only containers&#10;      - name: tmp-dir&#10;        emptyDir: &#123;&#125;&#10;      containers:&#10;      - name: metrics-server&#10;        image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.6&#10;        imagePullPolicy: Always&#10;        args:&#10;        - --kubelet-insecure-tls&#10;        - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP&#10;        volumeMounts:&#10;        - name: tmp-dir&#10;          mountPath: /tmp&#10;&#10;# &#23433;&#35013;metrics-server&#10;[root@master 1.8+]# kubectl apply -f ./&#10;&#10;# &#39564;&#35777;&#10;[root@master ~]# kubectl top node&#10;NAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%     &#10;node1    144m         7%     377Mi           21%         &#10;node2    186m         9%     351Mi           18%</span><br></pre></td></tr></table></figure>
</li>
<li><p>deployment和servie</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#21019;&#24314;deployment&#10;[root@master ~]# kubectl run nginx --image=nginx:1.17.1 --requests=cpu=100m -n dev&#10;deployment.apps/nginx created&#10;&#10;# &#21019;&#24314;service&#10;[root@master ~]# kubectl expose deploy nginx  --port=80 --target-port=80  --type=NodePort -n dev&#10;service/nginx exposed&#10;&#10;# &#26597;&#30475;&#10;[root@master ~]# kubectl get deployment,pod,svc -n dev&#10;NAME                    READY   UP-TO-DATE   AVAILABLE   AGE&#10;deployment.apps/nginx   1/1     1            1           47s&#10;&#10;NAME                         READY   STATUS    RESTARTS   AGE&#10;pod/nginx-7df9756ccc-bh8dr   1/1     Running   0          47s&#10;&#10;NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE&#10;service/nginx   NodePort   10.101.18.29   &#60;none&#62;        80:31830/TCP   35s</span><br></pre></td></tr></table></figure>
<p>创建pc-hpa.yaml文件：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: autoscaling/v1</span><br><span class="line"><span class="attribute">kind</span>: HorizontalPodAutoscaler</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: pc-hpa</span><br><span class="line">  <span class="attribute">namespace</span>: dev</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">minReplicas</span>: <span class="number">1</span>  #最小pod数量</span><br><span class="line">  <span class="attribute">maxReplicas</span>: <span class="number">10</span> #最大pod数量</span><br><span class="line">  <span class="attribute">targetCPUUtilizationPercentage</span>: <span class="number">3</span> # CPU使用率指标</span><br><span class="line">  <span class="attribute">scaleTargetRef</span>:   # 指定要控制的nginx信息</span><br><span class="line">    <span class="attribute">apiVersion</span>:  /v1</span><br><span class="line">    <span class="attribute">kind</span>: Deployment</span><br><span class="line">    <span class="attribute">name</span>: nginx</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#21019;&#24314;hpa&#10;[root@master ~]# kubectl create -f pc-hpa.yaml&#10;horizontalpodautoscaler.autoscaling/pc-hpa created&#10;&#10;# &#26597;&#30475;hpa&#10;[root@master ~]# kubectl get hpa -n dev&#10;NAME     REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE&#10;pc-hpa   Deployment/nginx   0%/3%     1         10        1          62s</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h6 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h6><p>对<code>http://192.168.36.10:30668/</code>压测，查看变化</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl get hpa -n dev -w&#10;NAME   REFERENCE      TARGETS  MINPODS  MAXPODS  REPLICAS  AGE&#10;pc-hpa  Deployment/nginx  0%/3%   1     10     1      4m11s&#10;pc-hpa  Deployment/nginx  0%/3%   1     10     1      5m19s&#10;pc-hpa  Deployment/nginx  22%/3%   1     10     1      6m50s&#10;pc-hpa  Deployment/nginx  22%/3%   1     10     4      7m5s&#10;pc-hpa  Deployment/nginx  22%/3%   1     10     8      7m21s&#10;pc-hpa  Deployment/nginx  6%/3%   1     10     8      7m51s&#10;pc-hpa  Deployment/nginx  0%/3%   1     10     8      9m6s&#10;pc-hpa  Deployment/nginx  0%/3%   1     10     8      13m&#10;pc-hpa  Deployment/nginx  0%/3%   1     10     1      14m</span><br></pre></td></tr></table></figure>
<p>剩下的控制器不做过多学习验证，用到的时候可以直接官方文档。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/06/06/K8s-Pod相关知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/06/K8s-Pod相关知识/" itemprop="url">K8s：Pod相关知识</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-06-06T21:49:32+08:00">
                2021-06-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/06/K8s-Pod相关知识/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/06/06/K8s-Pod相关知识/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Pod 是 Kubernetes 的一个最小调度以及资源单元。用户可以通过 Kubernetes 的 Pod API 生产一个 Pod，让 Kubernetes 对这个 Pod 进行调度，也就是把它放在某一个 Kubernetes 管理的节点上运行起来。</p>
<p>Pods内运行一个或者多个container，container之间共享pod的网络ip资源，存储volume资源，计算等资源，方便pod内部的container之间能够实现快速的访问和交互。</p>
<h4 id="Pod简单操作"><a href="#Pod简单操作" class="headerlink" title="Pod简单操作"></a>Pod简单操作</h4><p>kubernetes交互的方式通常分为四种：</p>
<ul>
<li>命令行，kubectl和kubernetes交互，完成资源的管理，命令行入门简单，但只能支持部分资源创建</li>
<li>API，通过resfulAPI以http的方式和kubernetes交互，适用于基于API做二次开发</li>
<li>SDK，提供各种语言原生的SDK，实现各种语言编程接入</li>
<li>YAML，通过易于理解的YAML文件格式，描述资源的定义，功能最丰富，最终转换为json格式</li>
</ul>
<p>kubernetes中通过定义生申明式的方式定义资源，即通过在yaml文件中定义所需的资源，kubernetes通过controller-manager按照yaml文件中定义的资源去生成所需的资源。通常在kubernetes中通过yaml文件的方式定义资源，然后通过kubectl create -f 文件.yaml的方式应用配置。</p>
<p>Pod资源清单</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1     #&#24517;&#36873;&#65292;&#29256;&#26412;&#21495;&#65292;&#20363;&#22914;v1&#10;kind: Pod       &#12288; #&#24517;&#36873;&#65292;&#36164;&#28304;&#31867;&#22411;&#65292;&#20363;&#22914; Pod&#10;metadata:       &#12288; #&#24517;&#36873;&#65292;&#20803;&#25968;&#25454;&#10;  name: string     #&#24517;&#36873;&#65292;Pod&#21517;&#31216;&#10;  namespace: string  #Pod&#25152;&#23646;&#30340;&#21629;&#21517;&#31354;&#38388;,&#40664;&#35748;&#20026;&#34;default&#34;&#10;  labels:       &#12288;&#12288;  #&#33258;&#23450;&#20041;&#26631;&#31614;&#21015;&#34920;&#10;    - name: string      &#12288;          &#10;spec:  #&#24517;&#36873;&#65292;Pod&#20013;&#23481;&#22120;&#30340;&#35814;&#32454;&#23450;&#20041;&#10;  containers:  #&#24517;&#36873;&#65292;Pod&#20013;&#23481;&#22120;&#21015;&#34920;&#10;  - name: string   #&#24517;&#36873;&#65292;&#23481;&#22120;&#21517;&#31216;&#10;    image: string  #&#24517;&#36873;&#65292;&#23481;&#22120;&#30340;&#38236;&#20687;&#21517;&#31216;&#10;    imagePullPolicy: [ Always|Never|IfNotPresent ]  #&#33719;&#21462;&#38236;&#20687;&#30340;&#31574;&#30053; &#10;    command: [string]   #&#23481;&#22120;&#30340;&#21551;&#21160;&#21629;&#20196;&#21015;&#34920;&#65292;&#22914;&#19981;&#25351;&#23450;&#65292;&#20351;&#29992;&#25171;&#21253;&#26102;&#20351;&#29992;&#30340;&#21551;&#21160;&#21629;&#20196;&#10;    args: [string]      #&#23481;&#22120;&#30340;&#21551;&#21160;&#21629;&#20196;&#21442;&#25968;&#21015;&#34920;&#10;    workingDir: string  #&#23481;&#22120;&#30340;&#24037;&#20316;&#30446;&#24405;&#10;    volumeMounts:       #&#25346;&#36733;&#21040;&#23481;&#22120;&#20869;&#37096;&#30340;&#23384;&#20648;&#21367;&#37197;&#32622;&#10;    - name: string      #&#24341;&#29992;pod&#23450;&#20041;&#30340;&#20849;&#20139;&#23384;&#20648;&#21367;&#30340;&#21517;&#31216;&#65292;&#38656;&#29992;volumes[]&#37096;&#20998;&#23450;&#20041;&#30340;&#30340;&#21367;&#21517;&#10;      mountPath: string #&#23384;&#20648;&#21367;&#22312;&#23481;&#22120;&#20869;mount&#30340;&#32477;&#23545;&#36335;&#24452;&#65292;&#24212;&#23569;&#20110;512&#23383;&#31526;&#10;      readOnly: boolean #&#26159;&#21542;&#20026;&#21482;&#35835;&#27169;&#24335;&#10;    ports: #&#38656;&#35201;&#26292;&#38706;&#30340;&#31471;&#21475;&#24211;&#21495;&#21015;&#34920;&#10;    - name: string        #&#31471;&#21475;&#30340;&#21517;&#31216;&#10;      containerPort: int  #&#23481;&#22120;&#38656;&#35201;&#30417;&#21548;&#30340;&#31471;&#21475;&#21495;&#10;      hostPort: int       #&#23481;&#22120;&#25152;&#22312;&#20027;&#26426;&#38656;&#35201;&#30417;&#21548;&#30340;&#31471;&#21475;&#21495;&#65292;&#40664;&#35748;&#19982;Container&#30456;&#21516;&#10;      protocol: string    #&#31471;&#21475;&#21327;&#35758;&#65292;&#25903;&#25345;TCP&#21644;UDP&#65292;&#40664;&#35748;TCP&#10;    env:   #&#23481;&#22120;&#36816;&#34892;&#21069;&#38656;&#35774;&#32622;&#30340;&#29615;&#22659;&#21464;&#37327;&#21015;&#34920;&#10;    - name: string  #&#29615;&#22659;&#21464;&#37327;&#21517;&#31216;&#10;      value: string #&#29615;&#22659;&#21464;&#37327;&#30340;&#20540;&#10;    resources: #&#36164;&#28304;&#38480;&#21046;&#21644;&#35831;&#27714;&#30340;&#35774;&#32622;&#10;      limits:  #&#36164;&#28304;&#38480;&#21046;&#30340;&#35774;&#32622;&#10;        cpu: string     #Cpu&#30340;&#38480;&#21046;&#65292;&#21333;&#20301;&#20026;core&#25968;&#65292;&#23558;&#29992;&#20110;docker run --cpu-shares&#21442;&#25968;&#10;        memory: string  #&#20869;&#23384;&#38480;&#21046;&#65292;&#21333;&#20301;&#21487;&#20197;&#20026;Mib/Gib&#65292;&#23558;&#29992;&#20110;docker run --memory&#21442;&#25968;&#10;      requests: #&#36164;&#28304;&#35831;&#27714;&#30340;&#35774;&#32622;&#10;        cpu: string    #Cpu&#35831;&#27714;&#65292;&#23481;&#22120;&#21551;&#21160;&#30340;&#21021;&#22987;&#21487;&#29992;&#25968;&#37327;&#10;        memory: string #&#20869;&#23384;&#35831;&#27714;,&#23481;&#22120;&#21551;&#21160;&#30340;&#21021;&#22987;&#21487;&#29992;&#25968;&#37327;&#10;    lifecycle: #&#29983;&#21629;&#21608;&#26399;&#38057;&#23376;&#10;        postStart: #&#23481;&#22120;&#21551;&#21160;&#21518;&#31435;&#21363;&#25191;&#34892;&#27492;&#38057;&#23376;,&#22914;&#26524;&#25191;&#34892;&#22833;&#36133;,&#20250;&#26681;&#25454;&#37325;&#21551;&#31574;&#30053;&#36827;&#34892;&#37325;&#21551;&#10;        preStop: #&#23481;&#22120;&#32456;&#27490;&#21069;&#25191;&#34892;&#27492;&#38057;&#23376;,&#26080;&#35770;&#32467;&#26524;&#22914;&#20309;,&#23481;&#22120;&#37117;&#20250;&#32456;&#27490;&#10;    livenessProbe:  #&#23545;Pod&#20869;&#21508;&#23481;&#22120;&#20581;&#24247;&#26816;&#26597;&#30340;&#35774;&#32622;&#65292;&#24403;&#25506;&#27979;&#26080;&#21709;&#24212;&#20960;&#27425;&#21518;&#23558;&#33258;&#21160;&#37325;&#21551;&#35813;&#23481;&#22120;&#10;      exec:       &#12288; #&#23545;Pod&#23481;&#22120;&#20869;&#26816;&#26597;&#26041;&#24335;&#35774;&#32622;&#20026;exec&#26041;&#24335;&#10;        command: [string]  #exec&#26041;&#24335;&#38656;&#35201;&#21046;&#23450;&#30340;&#21629;&#20196;&#25110;&#33050;&#26412;&#10;      httpGet:       #&#23545;Pod&#20869;&#20010;&#23481;&#22120;&#20581;&#24247;&#26816;&#26597;&#26041;&#27861;&#35774;&#32622;&#20026;HttpGet&#65292;&#38656;&#35201;&#21046;&#23450;Path&#12289;port&#10;        path: string&#10;        port: number&#10;        host: string&#10;        scheme: string&#10;        HttpHeaders:&#10;        - name: string&#10;          value: string&#10;      tcpSocket:     #&#23545;Pod&#20869;&#20010;&#23481;&#22120;&#20581;&#24247;&#26816;&#26597;&#26041;&#24335;&#35774;&#32622;&#20026;tcpSocket&#26041;&#24335;&#10;         port: number&#10;       initialDelaySeconds: 0       #&#23481;&#22120;&#21551;&#21160;&#23436;&#25104;&#21518;&#39318;&#27425;&#25506;&#27979;&#30340;&#26102;&#38388;&#65292;&#21333;&#20301;&#20026;&#31186;&#10;       timeoutSeconds: 0    &#12288;&#12288;    #&#23545;&#23481;&#22120;&#20581;&#24247;&#26816;&#26597;&#25506;&#27979;&#31561;&#24453;&#21709;&#24212;&#30340;&#36229;&#26102;&#26102;&#38388;&#65292;&#21333;&#20301;&#31186;&#65292;&#40664;&#35748;1&#31186;&#10;       periodSeconds: 0     &#12288;&#12288;    #&#23545;&#23481;&#22120;&#30417;&#25511;&#26816;&#26597;&#30340;&#23450;&#26399;&#25506;&#27979;&#26102;&#38388;&#35774;&#32622;&#65292;&#21333;&#20301;&#31186;&#65292;&#40664;&#35748;10&#31186;&#19968;&#27425;&#10;       successThreshold: 0&#10;       failureThreshold: 0&#10;       securityContext:&#10;         privileged: false&#10;  restartPolicy: [Always | Never | OnFailure]  #Pod&#30340;&#37325;&#21551;&#31574;&#30053;&#10;  nodeName: &#60;string&#62; #&#35774;&#32622;NodeName&#34920;&#31034;&#23558;&#35813;Pod&#35843;&#24230;&#21040;&#25351;&#23450;&#21040;&#21517;&#31216;&#30340;node&#33410;&#28857;&#19978;&#10;  nodeSelector: obeject #&#35774;&#32622;NodeSelector&#34920;&#31034;&#23558;&#35813;Pod&#35843;&#24230;&#21040;&#21253;&#21547;&#36825;&#20010;label&#30340;node&#19978;&#10;  imagePullSecrets: #Pull&#38236;&#20687;&#26102;&#20351;&#29992;&#30340;secret&#21517;&#31216;&#65292;&#20197;key&#65306;secretkey&#26684;&#24335;&#25351;&#23450;&#10;  - name: string&#10;  hostNetwork: false   #&#26159;&#21542;&#20351;&#29992;&#20027;&#26426;&#32593;&#32476;&#27169;&#24335;&#65292;&#40664;&#35748;&#20026;false&#65292;&#22914;&#26524;&#35774;&#32622;&#20026;true&#65292;&#34920;&#31034;&#20351;&#29992;&#23487;&#20027;&#26426;&#32593;&#32476;&#10;  volumes:   #&#22312;&#35813;pod&#19978;&#23450;&#20041;&#20849;&#20139;&#23384;&#20648;&#21367;&#21015;&#34920;&#10;  - name: string    #&#20849;&#20139;&#23384;&#20648;&#21367;&#21517;&#31216; &#65288;volumes&#31867;&#22411;&#26377;&#24456;&#22810;&#31181;&#65289;&#10;    emptyDir: &#123;&#125;       #&#31867;&#22411;&#20026;emtyDir&#30340;&#23384;&#20648;&#21367;&#65292;&#19982;Pod&#21516;&#29983;&#21629;&#21608;&#26399;&#30340;&#19968;&#20010;&#20020;&#26102;&#30446;&#24405;&#12290;&#20026;&#31354;&#20540;&#10;    hostPath: string   #&#31867;&#22411;&#20026;hostPath&#30340;&#23384;&#20648;&#21367;&#65292;&#34920;&#31034;&#25346;&#36733;Pod&#25152;&#22312;&#23487;&#20027;&#26426;&#30340;&#30446;&#24405;&#10;      path: string      &#12288;&#12288;        #Pod&#25152;&#22312;&#23487;&#20027;&#26426;&#30340;&#30446;&#24405;&#65292;&#23558;&#34987;&#29992;&#20110;&#21516;&#26399;&#20013;mount&#30340;&#30446;&#24405;&#10;    secret:       &#12288;&#12288;&#12288;#&#31867;&#22411;&#20026;secret&#30340;&#23384;&#20648;&#21367;&#65292;&#25346;&#36733;&#38598;&#32676;&#19982;&#23450;&#20041;&#30340;secret&#23545;&#35937;&#21040;&#23481;&#22120;&#20869;&#37096;&#10;      scretname: string  &#10;      items:     &#10;      - key: string&#10;        path: string&#10;    configMap:         #&#31867;&#22411;&#20026;configMap&#30340;&#23384;&#20648;&#21367;&#65292;&#25346;&#36733;&#39044;&#23450;&#20041;&#30340;configMap&#23545;&#35937;&#21040;&#23481;&#22120;&#20869;&#37096;&#10;      name: string&#10;      items:&#10;      - key: string&#10;        path: string</span><br></pre></td></tr></table></figure>
<p>这么多东西都记住不太可能，可以通过<code>kubectl explain</code>查到每个字段的含义，使用说明和使用方式。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[rootmaster ~]# kubectl explain pod&#10;KIND:     Pod&#10;VERSION:  v1&#10;FIELDS:&#10;   apiVersion   &#60;string&#62;&#10;   kind &#60;string&#62;&#10;   metadata     &#60;Object&#62;&#10;   spec &#60;Object&#62;&#10;   status       &#60;Object&#62;&#10;&#10;[root@master ~]# kubectl explain pod.metadata</span><br></pre></td></tr></table></figure>
<h6 id="创建Pod"><a href="#创建Pod" class="headerlink" title="创建Pod"></a>创建Pod</h6><p>创建 <code>pod-basic.yaml</code>文件</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1&#10;kind: Pod&#10;metadata:&#10;  name: pod-basic&#10;  namespace: dev&#10;spec:&#10;  containers:&#10;  - name: nginx&#10;    image: nginx:1.17.1&#10;    ports: # &#35774;&#32622;&#23481;&#22120;&#26292;&#38706;&#30340;&#31471;&#21475;&#21015;&#34920;&#10;    - name: nginx-port&#10;      containerPort: 80&#10;      protocol: TCP&#10;    imagePullPolicy: Never # &#29992;&#20110;&#35774;&#32622;&#38236;&#20687;&#25289;&#21462;&#31574;&#30053;&#10;  - name: busybox&#10;    image: busybox:1.30&#10;    command: [&#34;/bin/sh&#34;,&#34;-c&#34;,&#34;touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) &#62;&#62; /tmp/hello.txt; sleep 3; done;&#34;]</span><br></pre></td></tr></table></figure>
<p>上面定义了一个比较简单Pod的配置，里面有两个容器。</p>
<p>imagePullPolicy，用于设置镜像拉取策略，kubernetes支持配置三种拉取策略：</p>
<ul>
<li><p>Always：总是从远程仓库拉取镜像（一直远程下载）</p>
</li>
<li><p>IfNotPresent：本地有则使用本地镜像，本地没有则从远程仓库拉取镜像（本地有就本地 本地没远程下载）</p>
</li>
<li><p>Never：只使用本地镜像，从不去远程仓库拉取，本地没有就报错 （一直使用本地）</p>
<blockquote>
<p>如果镜像tag为具体版本号， 默认策略是：IfNotPresent</p>
<p>如果镜像tag为：latest（最终版本） ，默认策略是always</p>
</blockquote>
</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl create ns dev&#10;namespace/dev created&#10;[root@master ~]# kubectl create -f pod-basic.yaml &#10;Error from server (Forbidden): error when creating &#34;pod-basic.yaml&#34;: pods &#34;pod-basic&#34; is forbidden: error looking up service account dev/default: serviceaccount &#34;default&#34; not found&#10;# &#20462;&#29702; Error&#10;[root@master ~]# mkdir -p $HOME/.kube&#10;[root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config&#10;cp&#65306;&#26159;&#21542;&#35206;&#30422;&#34;/root/.kube/config&#34;&#65311; y&#10;[root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config&#10;&#10;[root@master ~]# kubectl create -f pod-basic.yaml &#10;pod/pod-basic created</span><br></pre></td></tr></table></figure>
<h6 id="查看Pod"><a href="#查看Pod" class="headerlink" title="查看Pod"></a>查看Pod</h6><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#26597;&#30475;Pod&#29366;&#24577;&#10;[root@master ~]# kubectl get pod -n dev&#10;NAME        READY   STATUS    RESTARTS   AGE&#10;pod-basic   2/2     Running   0          6m21s&#10;&#10;# &#26597;&#30475;Pod&#35814;&#32454;&#20449;&#24687;&#10;[root@master ~]# kubectl describe pod pod-basic -n dev&#10;Name:         pod-basic&#10;Namespace:    dev&#10;Priority:     0&#10;Node:         node1/192.168.36.11&#10;Start Time:   Fri, 15 Oct 2021 10:03:02 +0800&#10;Labels:       &#60;none&#62;&#10;Annotations:  &#60;none&#62;&#10;Status:       Running&#10;IP:           10.244.2.5&#10;IPs:&#10;  IP:  10.244.2.5&#10;Containers:&#10;  nginx:&#10;    Container ID:   docker://7898e9c6351803089656d74defbf979f7126b1c01a370499c27cd882658ecaec&#10;    Image:          nginx:1.17.1&#10;    Image ID:       docker-pullable://nginx@sha256:b4b9b3eee194703fc2fa8afa5b7510c77ae70cfba567af1376a573a967c03dbb&#10;    Port:           80/TCP&#10;    Host Port:      0/TCP&#10;    State:          Running&#10;      Started:      Fri, 15 Oct 2021 10:03:48 +0800&#10;    Ready:          True&#10;    Restart Count:  0&#10;    Environment:    &#60;none&#62;&#10;    Mounts:&#10;      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5kcqv (ro)&#10;  busybox:&#10;    Container ID:  docker://99731cc93e57c7a5551f32f672cdd0f8c69f2f5af59e39f8203bbf8b40de2034&#10;    Image:         busybox:1.30&#10;    Image ID:      docker-pullable://busybox@sha256:4b6ad3a68d34da29bf7c8ccb5d355ba8b4babcad1f99798204e7abb43e54ee3d&#10;    Port:          &#60;none&#62;&#10;    Host Port:     &#60;none&#62;&#10;    Command:&#10;      /bin/sh&#10;      -c&#10;      touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) &#62;&#62; /tmp/hello.txt; sleep 3; done;&#10;    State:          Running&#10;      Started:      Fri, 15 Oct 2021 10:03:48 +0800&#10;    Ready:          True&#10;    Restart Count:  0&#10;    Environment:    &#60;none&#62;&#10;    Mounts:&#10;      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5kcqv (ro)&#10;Conditions:&#10;  Type              Status&#10;  Initialized       True &#10;  Ready             True &#10;  ContainersReady   True &#10;  PodScheduled      True &#10;Volumes:&#10;  default-token-5kcqv:&#10;    Type:        Secret (a volume populated by a Secret)&#10;    SecretName:  default-token-5kcqv&#10;    Optional:    false&#10;QoS Class:       BestEffort&#10;Node-Selectors:  &#60;none&#62;&#10;Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s&#10;                 node.kubernetes.io/unreachable:NoExecute for 300s&#10;Events:&#10;  Type    Reason     Age        From               Message&#10;  ----    ------     ----       ----               -------&#10;  Normal  Scheduled  &#60;unknown&#62;  default-scheduler  Successfully assigned dev/pod-basic to node1&#10;  Normal  Pulling    3m14s      kubelet, node1     Pulling image &#34;nginx:1.17.1&#34;&#10;  Normal  Pulled     2m30s      kubelet, node1     Successfully pulled image &#34;nginx:1.17.1&#34;&#10;  Normal  Created    2m30s      kubelet, node1     Created container nginx&#10;  Normal  Started    2m29s      kubelet, node1     Started container nginx&#10;  Normal  Pulled     2m29s      kubelet, node1     Container image &#34;busybox:1.30&#34; already present on machine&#10;  Normal  Created    2m29s      kubelet, node1     Created container busybox&#10;  Normal  Started    2m29s      kubelet, node1     Started container busybox</span><br></pre></td></tr></table></figure>
<h6 id="进入Pod"><a href="#进入Pod" class="headerlink" title="进入Pod"></a>进入Pod</h6><p><code>kubectl exec  pod名称 -n 命名空间 -it -c 容器名称 command</code>使用这个命令就可以进入某个容器的内部，然后进行相关操作了</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl exec pod-basic -n dev -it -c busybox /bin/sh&#10;/ # tail -f /tmp/hello.txt &#10;02:12:46&#10;02:12:49&#10;02:12:52</span><br></pre></td></tr></table></figure>
<h6 id="资源配额"><a href="#资源配额" class="headerlink" title="资源配额"></a>资源配额</h6><p>容器中的程序要运行，肯定是要占用一定资源的，比如cpu和内存等，如果不对某个容器的资源做限制，那么它就可能吃掉大量资源，导致其它容器无法运行。针对这种情况，kubernetes提供了对内存和cpu的资源进行配额的机制，这种机制主要通过resources选项实现，他有两个子选项：</p>
<ul>
<li>limits：用于限制运行时容器的最大占用资源，当容器占用资源超过limits时会被终止，并进行重启</li>
<li>requests ：用于设置容器需要的最小资源，如果环境资源不够，容器将无法启动</li>
</ul>
<p>可以通过上面两个选项设置资源的上下限。</p>
<p>创建pod-resources.yaml</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1&#10;kind: Pod&#10;metadata:&#10;  name: pod-resources&#10;  namespace: dev&#10;spec:&#10;  containers:&#10;  - name: nginx&#10;    image: nginx:1.17.1&#10;    resources: # &#36164;&#28304;&#37197;&#39069;&#10;      limits:  # &#38480;&#21046;&#36164;&#28304;&#65288;&#19978;&#38480;&#65289;&#10;        cpu: &#34;2&#34; # CPU&#38480;&#21046;&#65292;&#21333;&#20301;&#26159;core&#25968;&#10;        memory: &#34;10Gi&#34; # &#20869;&#23384;&#38480;&#21046;&#10;      requests: # &#35831;&#27714;&#36164;&#28304;&#65288;&#19979;&#38480;&#65289;&#10;        cpu: &#34;1&#34;  # CPU&#38480;&#21046;&#65292;&#21333;&#20301;&#26159;core&#25968;&#10;        memory: &#34;10Mi&#34;  # &#20869;&#23384;&#38480;&#21046;</span><br></pre></td></tr></table></figure>
<ul>
<li>cpu：core数，可以为整数或小数</li>
<li>memory： 内存大小，可以使用Gi、Mi、G、M等形式</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#36816;&#34892;Pod&#10;[root@master ~]# kubectl create  -f pod-resources.yaml&#10;pod/pod-resources created&#10;&#10;# &#26597;&#30475;&#21457;&#29616;pod&#36816;&#34892;&#27491;&#24120;&#10;[root@master ~]# kubectl get pod pod-resources -n dev&#10;NAME            READY   STATUS    RESTARTS   AGE  &#10;pod-resources   1/1     Running   0          39s   &#10;&#10;# &#25509;&#19979;&#26469;&#65292;&#20572;&#27490;Pod&#10;[root@master ~]# kubectl delete  -f pod-resources.yaml&#10;pod &#34;pod-resources&#34; deleted&#10;&#10;# &#32534;&#36753;pod&#65292;&#20462;&#25913;resources.requests.memory&#30340;&#20540;&#20026;10Gi&#10;[root@master ~]# vim pod-resources.yaml&#10;&#10;# &#20877;&#27425;&#21551;&#21160;pod&#10;[root@master ~]# kubectl create  -f pod-resources.yaml&#10;pod/pod-resources created&#10;&#10;# &#26597;&#30475;Pod&#29366;&#24577;&#65292;&#21457;&#29616;Pod&#21551;&#21160;&#22833;&#36133;&#10;[root@master ~]# kubectl get pod pod-resources -n dev -o wide&#10;NAME            READY   STATUS    RESTARTS   AGE          &#10;pod-resources   0/1     Pending   0          20s    &#10;&#10;# &#26597;&#30475;pod&#35814;&#24773;&#20250;&#21457;&#29616;&#65292;&#22914;&#19979;&#25552;&#31034;&#10;[root@master ~]# kubectl describe pod pod-resources -n dev&#10;Events:&#10;  Type     Reason            Age        From               Message&#10;  ----     ------            ----       ----               -------&#10;  Warning  FailedScheduling  &#60;unknown&#62;  default-scheduler  0/3 nodes are available: 3 Insufficient memory.</span><br></pre></td></tr></table></figure>
<h4 id="Pod生命周期"><a href="#Pod生命周期" class="headerlink" title="Pod生命周期"></a>Pod生命周期</h4><p><img src="/images/k8s/life.jpg" alt=""></p>
<ul>
<li>运行初始化容器（init container）过程</li>
<li>运行主容器（main container）<ul>
<li>容器启动后钩子（post start）、容器终止前钩子（pre stop）</li>
<li>容器的存活性探测（liveness probe）、就绪性探测（readiness probe）</li>
</ul>
</li>
</ul>
<h6 id="Pod状态"><a href="#Pod状态" class="headerlink" title="Pod状态"></a>Pod状态</h6><p>在整个生命周期中，Pod会出现5种状态</p>
<ul>
<li>挂起（Pending）：apiserver已经创建了pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中</li>
<li>运行中（Running）：pod已经被调度至某节点，并且所有容器都已经被kubelet创建完成</li>
<li>成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启</li>
<li>失败（Failed）：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态</li>
<li>未知（Unknown）：apiserver无法正常获取到pod对象的状态信息，通常由网络通信失败所导致</li>
</ul>
<h6 id="Pod的创建过程"><a href="#Pod的创建过程" class="headerlink" title="Pod的创建过程"></a>Pod的创建过程</h6><p>①用户通过kubectl或其他API客户端提交Pod Spec给API Server。</p>
<p>②API Server尝试将Pod对象的相关信息存储到etcd中，等待写入操作完成，API Server返回确认信息到客户端。</p>
<p>③API Server开始反映etcd中的状态变化。</p>
<p>④所有的Kubernetes组件通过”watch”机制跟踪检查API Server上的相关信息变动。</p>
<p>⑤kube-scheduler（调度器）通过其”watcher”检测到API Server创建了新的Pod对象但是没有绑定到任何工作节点。</p>
<p>⑥kube-scheduler为Pod对象挑选一个工作节点并将结果信息更新到API Server。</p>
<p>⑦调度结果新消息由API Server更新到etcd，并且API Server也开始反馈该Pod对象的调度结果。</p>
<p>⑧Pod被调度到目标工作节点上的kubelet尝试在当前节点上调用docker engine进行启动容器，并将容器的状态结果返回到API Server。</p>
<p>⑨API Server将Pod信息存储到etcd系统中。</p>
<p>⑩在etcd确认写入操作完成，API Server将确认信息发送到相关的kubelet。</p>
<h6 id="初始化容器"><a href="#初始化容器" class="headerlink" title="初始化容器"></a>初始化容器</h6><p>初始化容器是在pod的主容器启动之前要运行的容器，主要是做一些主容器的前置工作，它具有两大特征：</p>
<ol>
<li>初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成</li>
<li>初始化容器必须按照定义的顺序执行，当且仅当前一个成功之后，后面的一个才能运行</li>
</ol>
<h6 id="Webhook"><a href="#Webhook" class="headerlink" title="Webhook"></a>Webhook</h6><p>kubernetes在主容器的启动之后和停止之前提供了两个钩子函数：</p>
<ul>
<li>post start：容器创建之后执行，如果失败了会重启容器</li>
<li>pre stop ：容器终止之前执行，执行完成之后容器将成功终止，在其完成之前会阻塞删除容器的操作</li>
</ul>
<p>钩子处理器支持使用下面三种方式定义动作：</p>
<p>钩子处理器支持使用下面三种方式定义动作：</p>
<ul>
<li><p>Exec命令：在容器内执行一次命令</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lifecycle:&#10;  postStart: &#10;    exec:&#10;      command:&#10;      - cat&#10;      - /tmp/healthy</span><br></pre></td></tr></table></figure>
</li>
<li><p>TCPSocket：在当前容器尝试访问指定的socket</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">lifecycle</span>:</span><br><span class="line">  <span class="attribute">postStart</span>:</span><br><span class="line">    <span class="attribute">tcpSocket</span>:</span><br><span class="line">      <span class="attribute">port</span>: <span class="number">8080</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>HTTPGet：在当前容器中向某url发起http请求</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lifecycle:</span><br><span class="line">  postStart:</span><br><span class="line">    httpGet:</span><br><span class="line">      path: / <span class="preprocessor">#URI地址</span></span><br><span class="line">      port: <span class="number">80</span> <span class="preprocessor">#端口号</span></span><br><span class="line">      host: <span class="number">192.168</span><span class="number">.5</span><span class="number">.3</span> <span class="preprocessor">#主机地址</span></span><br><span class="line">      scheme: HTTP <span class="preprocessor">#支持的协议，http或者https</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>创建pod-hook-exec.yaml文件</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1&#10;kind: Pod&#10;metadata:&#10;  name: pod-hook-exec&#10;  namespace: dev&#10;spec:&#10;  containers:&#10;  - name: main-container&#10;    image: nginx:1.17.1&#10;    ports:&#10;    - name: nginx-port&#10;      containerPort: 80&#10;    lifecycle:&#10;      postStart: &#10;        exec: # &#22312;&#23481;&#22120;&#21551;&#21160;&#30340;&#26102;&#20505;&#25191;&#34892;&#19968;&#20010;&#21629;&#20196;&#65292;&#20462;&#25913;&#25481;nginx&#30340;&#40664;&#35748;&#39318;&#39029;&#20869;&#23481;&#10;          command: [&#34;/bin/sh&#34;, &#34;-c&#34;, &#34;echo postStart... &#62; /usr/share/nginx/html/index.html&#34;]&#10;      preStop:&#10;        exec: # &#22312;&#23481;&#22120;&#20572;&#27490;&#20043;&#21069;&#20572;&#27490;nginx&#26381;&#21153;&#10;          command: [&#34;/usr/sbin/nginx&#34;,&#34;-s&#34;,&#34;quit&#34;]</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# vim pod-hook-exec.yaml&#10;[root@master ~]# kubectl create -f pod-hook-exec.yaml &#10;pod/pod-hook-exec created&#10;[root@master ~]# kubectl get pods  pod-hook-exec -n dev -o wide&#10;NAME            READY   STATUS    RESTARTS   AGE   IP           NODE    NOMINATED NODE   READINESS GATES&#10;pod-hook-exec   1/1     Running   0          28s   10.244.2.7   node1   &#60;none&#62;           &#60;none&#62;&#10;[root@master ~]# curl 10.244.2.7&#10;postStart...</span><br></pre></td></tr></table></figure>
<h6 id="容器探测"><a href="#容器探测" class="headerlink" title="容器探测"></a>容器探测</h6><p>容器探测用于检测容器中的应用实例是否正常工作，是保障业务可用性的一种传统机制。如果经过探测，实例的状态不符合预期，那么kubernetes就会把该问题实例” 摘除 “，不承担业务流量。kubernetes提供了两种探针来实现容器探测，分别是：</p>
<ul>
<li>liveness probes：存活性探针，用于检测应用实例当前是否处于正常运行状态，如果不是，k8s会重启容器</li>
<li>readiness probes：就绪性探针，用于检测应用实例当前是否可以接收请求，如果不能，k8s不会转发流量</li>
</ul>
<blockquote>
<p>livenessProbe 决定是否重启容器，readinessProbe 决定是否将请求转发给容器。</p>
</blockquote>
<p>上面两种探针目前均支持三种探测方式：</p>
<ul>
<li>Exec命令：在容器内执行一次命令，如果命令执行的退出码为0，则认为程序正常，否则不正常</li>
<li>TCPSocket：将会尝试访问一个用户容器的端口，如果能够建立这条连接，则认为程序正常，否则不正常</li>
<li>HTTPGet：调用容器内Web应用的URL，如果返回的状态码在200和399之间，则认为程序正常，否则不正常</li>
</ul>
<p>创建pod-liveness-tcpsocket.yaml</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1&#10;kind: Pod&#10;metadata:&#10;  name: pod-liveness-tcpsocket&#10;  namespace: dev&#10;spec:&#10;  containers:&#10;  - name: nginx&#10;    image: nginx:1.17.1&#10;    ports: &#10;    - name: nginx-port&#10;      containerPort: 80&#10;    livenessProbe:&#10;      tcpSocket:&#10;        port: 8080 # &#23581;&#35797;&#35775;&#38382;8080&#31471;&#21475;</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# vi pod-liveness-tcpsocket.yaml&#10;[root@master ~]# kubectl create -f pod-liveness-tcpsocket.yaml &#10;pod/pod-liveness-tcpsocket created&#10;&#10;# &#26597;&#30475;Pod&#35814;&#24773;&#10;[root@master ~]# kubectl describe pods pod-liveness-tcpsocket -n dev&#10;Events:&#10;  Type     Reason     Age        From               Message&#10;  ----     ------     ----       ----               -------&#10;  Normal   Scheduled  &#60;unknown&#62;  default-scheduler  Successfully assigned dev/pod-liveness-tcpsocket to node1&#10;  Normal   Pulled     14s        kubelet, node1     Container image &#34;nginx:1.17.1&#34; already present on machine&#10;  Normal   Created    14s        kubelet, node1     Created container nginx&#10;  Normal   Started    13s        kubelet, node1     Started container nginx&#10;  Warning  Unhealthy  7s         kubelet, node1     Liveness probe failed: dial tcp 10.244.2.8:8080: connect: connection refused&#10;&#10;# &#31245;&#31561;&#19968;&#20250;&#20043;&#21518;&#65292;&#20877;&#35266;&#23519;pod&#20449;&#24687;&#65292;&#23601;&#21487;&#20197;&#30475;&#21040;RESTARTS&#19981;&#20877;&#26159;0&#65292;&#32780;&#26159;&#19968;&#30452;&#22686;&#38271;&#10;[root@master ~]# kubectl get pods pod-liveness-tcpsocket  -n dev&#10;NAME                     READY   STATUS    RESTARTS   AGE&#10;pod-liveness-tcpsocket   1/1     Running   3          2m50s</span><br></pre></td></tr></table></figure>
<h6 id="重启策略"><a href="#重启策略" class="headerlink" title="重启策略"></a>重启策略</h6><p>一旦容器探测出现了问题，kubernetes就会对容器所在的Pod进行重启，其实这是由pod的重启策略决定的，pod的重启策略有 3 种，分别如下：</p>
<ul>
<li>Always ：容器失效时，自动重启该容器，这也是默认值。</li>
<li>OnFailure ： 容器终止运行且退出码不为0时重启</li>
<li>Never ： 不论状态为何，都不重启该容器</li>
</ul>
<p>重启策略适用于pod对象中的所有容器，首次需要重启的容器，将在其需要时立即进行重启，随后再次需要重启的操作将由kubelet延迟一段时间后进行，且反复的重启操作的延迟时长以此为10s、20s、40s、80s、160s和300s，300s是最大延迟时长。</p>
<p>创建pod-restartpolicy.yaml</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1&#10;kind: Pod&#10;metadata:&#10;  name: pod-restartpolicy&#10;  namespace: dev&#10;spec:&#10;  containers:&#10;  - name: nginx&#10;    image: nginx:1.17.1&#10;    ports:&#10;    - name: nginx-port&#10;      containerPort: 80&#10;    livenessProbe:&#10;      httpGet:&#10;        scheme: HTTP&#10;        port: 80&#10;        path: /hello&#10;  restartPolicy: Never # &#35774;&#32622;&#37325;&#21551;&#31574;&#30053;&#20026;Never</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl create -f pod-restartpolicy.yaml&#10;pod/pod-restartpolicy created&#10;&#10;# &#26597;&#30475;Pod&#35814;&#24773;&#10;[root@master ~]# kubectl  describe pods pod-restartpolicy  -n dev&#10;......&#10;  Warning  Unhealthy  15s (x3 over 35s)  kubelet, node1     Liveness probe failed: HTTP probe failed with statuscode: 404&#10;  Normal   Killing    15s                kubelet, node1     Container nginx failed liveness probe&#10;  &#10;# &#22810;&#31561;&#19968;&#20250;&#65292;&#20877;&#35266;&#23519;pod&#30340;&#37325;&#21551;&#27425;&#25968;&#65292;&#21457;&#29616;&#19968;&#30452;&#26159;0&#65292;&#24182;&#26410;&#37325;&#21551;   &#10;[root@master ~]# kubectl  get pods pod-restartpolicy -n dev&#10;NAME                   READY   STATUS    RESTARTS   AGE&#10;pod-restartpolicy      0/1     Running   0          5min42s</span><br></pre></td></tr></table></figure>
<h4 id="Pod调度"><a href="#Pod调度" class="headerlink" title="Pod调度"></a>Pod调度</h4><p>在默认情况下，一个Pod在哪个Node节点上运行，是由Scheduler组件采用相应的算法计算出来的，这个过程是不受人工控制的。但是在实际使用中，这并不满足的需求，因为很多情况下，我们想控制某些Pod到达某些节点上，那么应该怎么做呢？这就要求了解kubernetes对Pod的调度规则，kubernetes提供了四大类调度方式：</p>
<ul>
<li>自动调度：运行在哪个节点上完全由Scheduler经过一系列的算法计算得出</li>
<li>定向调度：NodeName、NodeSelector</li>
<li>亲和性调度：NodeAffinity、PodAffinity、PodAntiAffinity</li>
<li>污点（容忍）调度：Taints、Toleration</li>
</ul>
<h6 id="定向调度"><a href="#定向调度" class="headerlink" title="定向调度"></a>定向调度</h6><p>定向调度，指的是利用在pod上声明nodeName或者nodeSelector，以此将Pod调度到期望的node节点上。注意，这里的调度是强制的，这就意味着即使要调度的目标Node不存在，也会向上面进行调度，只不过pod运行失败而已。</p>
<ul>
<li><p>nodeName调度</p>
<p>NodeName用于强制约束将Pod调度到指定的Name的Node节点上。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1&#10;kind: Pod&#10;metadata:&#10;  name: pod-nodename&#10;  namespace: dev&#10;spec:&#10;  containers:&#10;  - name: nginx&#10;    image: nginx:1.17.1&#10;  nodeName: node1 # &#25351;&#23450;&#35843;&#24230;&#21040;node1&#33410;&#28857;&#19978;</span><br></pre></td></tr></table></figure>
</li>
<li><p>nodeSelector调度</p>
<p>NodeSelector用于将pod调度到添加了指定标签的node节点上。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1&#10;kind: Pod&#10;metadata:&#10;  name: pod-nodeselector&#10;  namespace: dev&#10;spec:&#10;  containers:&#10;  - name: nginx&#10;    image: nginx:1.17.1&#10;  nodeSelector: &#10;    nodeenv: dev # &#25351;&#23450;&#35843;&#24230;&#21040;&#20855;&#26377;nodeenv=dev&#26631;&#31614;&#30340;&#33410;&#28857;&#19978;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h6 id="亲和性调度"><a href="#亲和性调度" class="headerlink" title="亲和性调度"></a>亲和性调度</h6><p>kubernetes还提供了一种亲和性调度（Affinity）。它在NodeSelector的基础之上的进行了扩展，可以通过配置的形式，实现优先选择满足条件的Node进行调度，如果没有，也可以调度到不满足条件的节点上，使调度更加灵活。</p>
<p>Affinity主要分为三类：</p>
<ul>
<li><p>nodeAffinity(node亲和性）: 以node为目标，解决pod可以调度到哪些node的问题</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pod.spec.affinity.nodeAffinity&#10;  requiredDuringSchedulingIgnoredDuringExecution  Node&#33410;&#28857;&#24517;&#39035;&#28385;&#36275;&#25351;&#23450;&#30340;&#25152;&#26377;&#35268;&#21017;&#25165;&#21487;&#20197;&#65292;&#30456;&#24403;&#20110;&#30828;&#38480;&#21046;&#10;    nodeSelectorTerms  &#33410;&#28857;&#36873;&#25321;&#21015;&#34920;&#10;      matchFields   &#25353;&#33410;&#28857;&#23383;&#27573;&#21015;&#20986;&#30340;&#33410;&#28857;&#36873;&#25321;&#22120;&#35201;&#27714;&#21015;&#34920;&#10;      matchExpressions   &#25353;&#33410;&#28857;&#26631;&#31614;&#21015;&#20986;&#30340;&#33410;&#28857;&#36873;&#25321;&#22120;&#35201;&#27714;&#21015;&#34920;(&#25512;&#33616;)&#10;        key    &#38190;&#10;        values &#20540;&#10;        operat or &#20851;&#31995;&#31526; &#25903;&#25345;Exists, DoesNotExist, In, NotIn, Gt, Lt&#10;  preferredDuringSchedulingIgnoredDuringExecution &#20248;&#20808;&#35843;&#24230;&#21040;&#28385;&#36275;&#25351;&#23450;&#30340;&#35268;&#21017;&#30340;Node&#65292;&#30456;&#24403;&#20110;&#36719;&#38480;&#21046; (&#20542;&#21521;)&#10;    preference   &#19968;&#20010;&#33410;&#28857;&#36873;&#25321;&#22120;&#39033;&#65292;&#19982;&#30456;&#24212;&#30340;&#26435;&#37325;&#30456;&#20851;&#32852;&#10;      matchFields   &#25353;&#33410;&#28857;&#23383;&#27573;&#21015;&#20986;&#30340;&#33410;&#28857;&#36873;&#25321;&#22120;&#35201;&#27714;&#21015;&#34920;&#10;      matchExpressions   &#25353;&#33410;&#28857;&#26631;&#31614;&#21015;&#20986;&#30340;&#33410;&#28857;&#36873;&#25321;&#22120;&#35201;&#27714;&#21015;&#34920;(&#25512;&#33616;)&#10;        key    &#38190;&#10;        values &#20540;&#10;        operator &#20851;&#31995;&#31526; &#25903;&#25345;In, NotIn, Exists, DoesNotExist, Gt, Lt&#10;&#9;weight &#20542;&#21521;&#26435;&#37325;&#65292;&#22312;&#33539;&#22260;1-100&#12290;</span><br></pre></td></tr></table></figure>
</li>
<li><p>podAffinity(pod亲和性) : 以pod为目标，解决pod可以和哪些已存在的pod部署在同一个拓扑域中的问题</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pod.spec.affinity.podAffinity&#10;  requiredDuringSchedulingIgnoredDuringExecution  &#30828;&#38480;&#21046;&#10;    namespaces       &#25351;&#23450;&#21442;&#29031;pod&#30340;namespace&#10;    topologyKey      &#25351;&#23450;&#35843;&#24230;&#20316;&#29992;&#22495;&#10;    labelSelector    &#26631;&#31614;&#36873;&#25321;&#22120;&#10;      matchExpressions  &#25353;&#33410;&#28857;&#26631;&#31614;&#21015;&#20986;&#30340;&#33410;&#28857;&#36873;&#25321;&#22120;&#35201;&#27714;&#21015;&#34920;(&#25512;&#33616;)&#10;        key    &#38190;&#10;        values &#20540;&#10;        operator &#20851;&#31995;&#31526; &#25903;&#25345;In, NotIn, Exists, DoesNotExist.&#10;      matchLabels    &#25351;&#22810;&#20010;matchExpressions&#26144;&#23556;&#30340;&#20869;&#23481;&#10;  preferredDuringSchedulingIgnoredDuringExecution &#36719;&#38480;&#21046;&#10;    podAffinityTerm  &#36873;&#39033;&#10;      namespaces      &#10;      topologyKey&#10;      labelSelector&#10;        matchExpressions  &#10;          key    &#38190;&#10;          values &#20540;&#10;          operator&#10;        matchLabels &#10;    weight &#20542;&#21521;&#26435;&#37325;&#65292;&#22312;&#33539;&#22260;1-100</span><br></pre></td></tr></table></figure>
</li>
<li><p>podAntiAffinity(pod反亲和性) : 以pod为目标，解决pod不能和哪些已存在pod部署在同一个拓扑域中的问题</p>
</li>
</ul>
<h6 id="污点和容忍"><a href="#污点和容忍" class="headerlink" title="污点和容忍"></a>污点和容忍</h6><ul>
<li><p>污点（Taints）</p>
<p>通过在Node上添加污点属性，来决定是否允许Pod调度过来</p>
<p>污点的格式为：<code>key=value:effect</code>, key和value是污点的标签，effect描述污点的作用，支持如下三个选项：</p>
<ul>
<li>PreferNoSchedule：kubernetes将尽量避免把Pod调度到具有该污点的Node上，除非没有其他节点可调度</li>
<li>NoSchedule：kubernetes将不会把Pod调度到具有该污点的Node上，但不会影响当前Node上已存在的Pod</li>
<li>NoExecute：kubernetes将不会把Pod调度到具有该污点的Node上，同时也会将Node上已存在的Pod驱离</li>
</ul>
<p>使用kubectl设置和去除污点的命令示例如下：</p>
<figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor"># 设置污点</span></span><br><span class="line">kubectl taint nodes node1 key=value:effect</span><br><span class="line"></span><br><span class="line"><span class="preprocessor"># 去除污点</span></span><br><span class="line">kubectl taint nodes node1 key:effect-</span><br><span class="line"></span><br><span class="line"><span class="preprocessor"># 去除所有污点</span></span><br><span class="line">kubectl taint nodes node1 key-</span><br></pre></td></tr></table></figure>
</li>
<li><p>容忍（Toleration）</p>
<p>污点就是拒绝，容忍就是忽略，Node通过污点拒绝pod调度上去，Pod通过容忍忽略拒绝</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/05/25/K8s-Namespace-Label/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/25/K8s-Namespace-Label/" itemprop="url">K8s：Namespace & Label</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-05-25T13:56:31+08:00">
                2021-05-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/05/25/K8s-Namespace-Label/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/05/25/K8s-Namespace-Label/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h4><p>Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现<strong>多套环境的资源隔离</strong>或者<strong>多租户的资源隔离</strong>。</p>
<p>默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的”组”，以方便不同的组的资源进行隔离使用和管理。</p>
<p>可以通过kubernetes的授权机制，将不同的namespace交给不同租户进行管理，这样就实现了多租户的资源隔离。此时还能结合kubernetes的资源配额机制，限定不同租户能占用的资源，例如CPU使用量、内存使用量等等，来实现租户可用资源的管理。</p>
<p>kubernetes在集群启动之后，会默认创建几个namespace</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl  get namespace&#10;NAME              STATUS   AGE&#10;default           Active   45h     #  &#25152;&#26377;&#26410;&#25351;&#23450;Namespace&#30340;&#23545;&#35937;&#37117;&#20250;&#34987;&#20998;&#37197;&#22312;default&#21629;&#21517;&#31354;&#38388;&#10;kube-node-lease   Active   45h     #  &#38598;&#32676;&#33410;&#28857;&#20043;&#38388;&#30340;&#24515;&#36339;&#32500;&#25252;&#65292;v1.13&#24320;&#22987;&#24341;&#20837;&#10;kube-public       Active   45h     #  &#27492;&#21629;&#21517;&#31354;&#38388;&#19979;&#30340;&#36164;&#28304;&#21487;&#20197;&#34987;&#25152;&#26377;&#20154;&#35775;&#38382;&#65288;&#21253;&#25324;&#26410;&#35748;&#35777;&#29992;&#25143;&#65289;&#10;kube-system       Active   45h     #  &#25152;&#26377;&#30001;Kubernetes&#31995;&#32479;&#21019;&#24314;&#30340;&#36164;&#28304;&#37117;&#22788;&#20110;&#36825;&#20010;&#21629;&#21517;&#31354;&#38388;</span><br></pre></td></tr></table></figure>
<p>基本的操作</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">create</span>/<span class="built_in">get</span>/<span class="built_in">delete</span> ns dev</span><br></pre></td></tr></table></figure>
<h4 id="Label"><a href="#Label" class="headerlink" title="Label"></a>Label</h4><p>Label是kubernetes系统中的一个重要概念。它的作用就是在资源上添加标识，用来对它们进行区分和选择。</p>
<p>Label的特点：</p>
<ul>
<li>一个Label会以key/value键值对的形式附加到各种对象上，如Node、Pod、Service等等</li>
<li>一个资源对象可以定义任意数量的Label ，同一个Label也可以被添加到任意数量的资源对象上去</li>
<li>Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除</li>
</ul>
<p>可以通过Label实现资源的多维度分组，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。</p>
<p>标签定义完毕之后，还要考虑到标签的选择，这就要使用到Label Selector，即：</p>
<ul>
<li><p>基于等式的Label Selector</p>
<p>name = slave: 选择所有包含Label中key=”name”且value=”slave”的对象</p>
<p>env != production: 选择所有包括Label中的key=”env”且value不等于”production”的对象</p>
</li>
<li><p>基于集合的Label Selector</p>
<p>name in (master, slave): 选择所有包含Label中的key=”name”且value=”master”或”slave”的对象</p>
<p>name not in (frontend): 选择所有包含Label中的key=”name”且value不等于”frontend”的对象</p>
</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#20026;pod&#36164;&#28304;&#25171;&#26631;&#31614;&#10;[root@master ~]# kubectl label pod nginx-pod version=1.0 -n dev&#10;pod/nginx-pod labeled&#10;&#10;# &#20026;pod&#36164;&#28304;&#26356;&#26032;&#26631;&#31614;&#10;[root@master ~]# kubectl label pod nginx-pod version=2.0 -n dev --overwrite&#10;pod/nginx-pod labeled&#10;&#10;# &#26597;&#30475;&#26631;&#31614;&#10;[root@master ~]# kubectl get pod nginx-pod  -n dev --show-labels&#10;NAME        READY   STATUS    RESTARTS   AGE   LABELS&#10;nginx-pod   1/1     Running   0          10m   version=2.0&#10;&#10;# &#31579;&#36873;&#26631;&#31614;&#10;[root@master ~]# kubectl get pod -n dev -l version=2.0  --show-labels&#10;NAME        READY   STATUS    RESTARTS   AGE   LABELS&#10;nginx-pod   1/1     Running   0          17m   version=2.0&#10;[root@master ~]# kubectl get pod -n dev -l version!=2.0 --show-labels&#10;No resources found in dev namespace.&#10;&#10;#&#21024;&#38500;&#26631;&#31614;&#10;[root@master ~]# kubectl label pod nginx-pod version- -n dev&#10;pod/nginx-pod labeled</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/05/17/K8s集群环境搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/17/K8s集群环境搭建/" itemprop="url">K8s：集群环境搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-05-17T21:39:36+08:00">
                2021-05-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/05/17/K8s集群环境搭建/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/05/17/K8s集群环境搭建/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<h4 id="Kubeadm-是一个K8s-部署工具，提供kubeadm-init-和kubeadm-join，用于快速部署Kubernetes-集群。"><a href="#Kubeadm-是一个K8s-部署工具，提供kubeadm-init-和kubeadm-join，用于快速部署Kubernetes-集群。" class="headerlink" title="Kubeadm 是一个K8s 部署工具，提供kubeadm init 和kubeadm join，用于快速部署Kubernetes 集群。"></a>Kubeadm 是一个K8s 部署工具，提供kubeadm init 和kubeadm join，用于快速部署Kubernetes 集群。</h4><ul>
<li>创建一个Master 节点kubeadm init</li>
<li>将Node 节点加入到当前集群中$ kubeadm join <master 节点的ip="" 和端口=""></master></li>
</ul>
</blockquote>
<h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><ul>
<li>VMWare</li>
<li>Centos 7.9 (3台)</li>
</ul>
<table>
<thead>
<tr>
<th>角色</th>
<th>IP</th>
</tr>
</thead>
<tbody>
<tr>
<td>master</td>
<td>192.168.36.10</td>
</tr>
<tr>
<td>node1</td>
<td>192.168.36.11</td>
</tr>
<tr>
<td>node2</td>
<td>192.168.36.12</td>
</tr>
</tbody>
</table>
<h4 id="系统安装和配置"><a href="#系统安装和配置" class="headerlink" title="系统安装和配置"></a>系统安装和配置</h4><p>VM的创建就不累述了，CPU 2C、MEM 2G、HARDWARE 40G、配置好网络（固定IP）、基础设施服务器。</p>
<ol>
<li><p>为了方便集群节点间的直接调用，在这个配置一下主机名解析</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.36.10 master&#10;192.168.36.11 node1&#10;192.168.36.12 node2</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置时间同步</p>
<p>kubernetes要求集群中的节点时间必须精确一致</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# systemctl start chronyd&#10;[root@master ~]# systemctl enable chronyd</span><br></pre></td></tr></table></figure>
</li>
<li><p>禁用防火墙</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# systemctl stop firewalld&#10;[root@master ~]# systemctl disable firewalld</span><br></pre></td></tr></table></figure>
</li>
<li><p>禁用Selinux</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#32534;&#36753; /etc/selinux/config &#25991;&#20214;&#65292;&#20462;&#25913;SELINUX&#30340;&#20540;&#20026;disable&#10;# &#27880;&#24847;&#20462;&#25913;&#23436;&#27605;&#20043;&#21518;&#38656;&#35201;&#37325;&#21551;linux&#26381;&#21153;&#10;SELINUX=disabled</span><br></pre></td></tr></table></figure>
</li>
<li><p>禁用Swap</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#32534;&#36753;&#20998;&#21306;&#37197;&#32622;&#25991;&#20214;/etc/fstab&#65292;&#27880;&#37322;&#25481;swap&#20998;&#21306;&#19968;&#34892;&#10;# &#27880;&#24847;&#20462;&#25913;&#23436;&#27605;&#20043;&#21518;&#38656;&#35201;&#37325;&#21551;linux&#26381;&#21153;&#10;vim /etc/fstab&#10;# /dev/mapper/centos-swap swap</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改内核参数</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#20462;&#25913;linux&#30340;&#20869;&#26680;&#37319;&#32435;&#25968;&#65292;&#28155;&#21152;&#32593;&#26725;&#36807;&#28388;&#21644;&#22320;&#22336;&#36716;&#21457;&#21151;&#33021;&#10;# &#32534;&#36753;/etc/sysctl.d/kubernetes.conf&#25991;&#20214;&#65292;&#28155;&#21152;&#22914;&#19979;&#37197;&#32622;&#65306;&#10;net.bridge.bridge-nf-call-ip6tables = 1&#10;net.bridge.bridge-nf-call-iptables = 1&#10;net.ipv4.ip_forward = 1&#10;&#10;# &#37325;&#26032;&#21152;&#36733;&#37197;&#32622;&#10;[root@master ~]# sysctl -p&#10;# &#21152;&#36733;&#32593;&#26725;&#36807;&#28388;&#27169;&#22359;&#10;[root@master ~]# modprobe br_netfilter&#10;# &#26597;&#30475;&#32593;&#26725;&#36807;&#28388;&#27169;&#22359;&#26159;&#21542;&#21152;&#36733;&#25104;&#21151;&#10;[root@master ~]# lsmod | grep br_netfilter</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置ipvs功能</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 1.&#23433;&#35013;ipset&#21644;ipvsadm&#10;[root@master ~]# yum install ipset ipvsadmin -y&#10;# 2.&#28155;&#21152;&#38656;&#35201;&#21152;&#36733;&#30340;&#27169;&#22359;&#20889;&#20837;&#33050;&#26412;&#25991;&#20214;&#10;[root@master ~]# cat &#60;&#60;EOF&#62; /etc/sysconfig/modules/ipvs.modules&#10;#!/bin/bash&#10;modprobe -- ip_vs&#10;modprobe -- ip_vs_rr&#10;modprobe -- ip_vs_wrr&#10;modprobe -- ip_vs_sh&#10;modprobe -- nf_conntrack_ipv4&#10;EOF&#10;# 3.&#20026;&#33050;&#26412;&#28155;&#21152;&#25191;&#34892;&#26435;&#38480;&#10;[root@master ~]# chmod +x /etc/sysconfig/modules/ipvs.modules&#10;# 4.&#25191;&#34892;&#33050;&#26412;&#25991;&#20214;&#10;[root@master ~]# /bin/bash /etc/sysconfig/modeules/ipvs.modules&#10;# 5.&#26597;&#30475;&#23545;&#24212;&#30340;&#27169;&#22359;&#26159;&#21542;&#21152;&#36733;&#25104;&#21151;&#10;[root@master ~]# lsmod | grep -e -ip_vs -e nf_conntrack_ipv4</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker安装</h4><p>三个VM上都安装。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 1&#12289;&#20999;&#25442;&#38236;&#20687;&#28304;&#10;[root@master ~]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d.docker-ce.repo&#10;&#10;# 2&#12289;&#26597;&#30475;&#24403;&#21069;&#38236;&#20687;&#28304;&#20013;&#25903;&#25345;&#30340;docker&#29256;&#26412;&#10;# &#20808;&#25191;&#34892;&#19968;&#19979;&#65288;yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo&#65289;&#10;[root@master ~]# yum list docker-ce --showduplicates&#10;&#10;# 3&#12289;&#23433;&#35013;&#29305;&#23450;&#29256;&#26412;&#30340;docker-ce&#10;# &#24517;&#39035;&#21046;&#23450;--setopt=obsoletes=0&#65292;&#21542;&#21017;yum&#20250;&#33258;&#21160;&#23433;&#35013;&#26356;&#39640;&#29256;&#26412;&#10;[root@master ~]# yum install --setopt=obsoletes=0 docker-ce-18.06.3.ce-3.el7 -y&#10;&#10;# 4&#12289;&#28155;&#21152;&#19968;&#20010;&#37197;&#32622;&#25991;&#20214;&#10;#Docker &#22312;&#40664;&#35748;&#24773;&#20917;&#19979;&#20351;&#29992;Vgroup Driver&#20026;cgroupfs&#65292;&#32780;Kubernetes&#25512;&#33616;&#20351;&#29992;systemd&#26469;&#26367;&#20195;cgroupfs&#10;[root@master ~]# mkdir /etc/docker&#10;[root@master ~]# cat &#60;&#60;EOF&#62; /etc/docker/daemon.json&#10;&#123;&#10;&#9;&#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],&#10;&#9;&#34;registry-mirrors&#34;: [&#34;https://kn0t2bca.mirror.aliyuncs.com&#34;]&#10;&#125;&#10;EOF&#10;&#10;# 5&#12289;&#21551;&#21160;dokcer&#10;[root@master ~]# systemctl restart docker&#10;[root@master ~]# systemctl enable docker&#10;&#10;# 6&#12289;&#39564;&#35777;&#10;[root@master ~]# docker version&#10;Client:&#10; Version:           18.06.3-ce&#10; API version:       1.38&#10; Go version:        go1.10.3&#10; Git commit:        d7080c1&#10; Built:             Wed Feb 20 02:26:51 2019&#10; OS/Arch:           linux/amd64&#10; Experimental:      false&#10;&#10;Server:&#10; Engine:&#10;  Version:          18.06.3-ce&#10;  API version:      1.38 (minimum version 1.12)&#10;  Go version:       go1.10.3&#10;  Git commit:       d7080c1&#10;  Built:            Wed Feb 20 02:28:17 2019&#10;  OS/Arch:          linux/amd64&#10;  Experimental:     false</span><br></pre></td></tr></table></figure>
<h4 id="K8s安装"><a href="#K8s安装" class="headerlink" title="K8s安装"></a>K8s安装</h4><h6 id="安装组件"><a href="#安装组件" class="headerlink" title="安装组件"></a>安装组件</h6><p>kubernetes的镜像在国外，速度比较慢，这里切换成国内的镜像源</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 1&#12289;&#32534;&#36753;/etc/yum.repos.d/kubernetes.repo,&#28155;&#21152;&#19979;&#38754;&#30340;&#37197;&#32622;&#10;[kubernetes]&#10;name=Kubernetes&#10;baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64&#10;enabled=1&#10;gpgchech=0&#10;repo_gpgcheck=0&#10;gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg&#10;&#9;&#9;&#9;http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg&#10;&#10;# 2&#12289;&#23433;&#35013;kubeadm&#12289;kubelet&#21644;kubectl&#10;[root@master ~]# yum install --setopt=obsoletes=0 kubeadm-1.17.4-0 kubelet-1.17.4-0 kubectl-1.17.4-0 -y&#10;&#10;# 3&#12289;&#37197;&#32622;kubelet&#30340;cgroup&#10;#&#32534;&#36753;/etc/sysconfig/kubelet, &#28155;&#21152;&#19979;&#38754;&#30340;&#37197;&#32622;&#10;KUBELET_CGROUP_ARGS=&#34;--cgroup-driver=systemd&#34;&#10;KUBE_PROXY_MODE=&#34;ipvs&#34;&#10;&#10;# 4&#12289;&#35774;&#32622;kubelet&#24320;&#26426;&#33258;&#21551;&#10;[root@master ~]# systemctl enable kubelet</span><br></pre></td></tr></table></figure>
<h6 id="准备集群镜像"><a href="#准备集群镜像" class="headerlink" title="准备集群镜像"></a>准备集群镜像</h6><p>Kubernetes几乎所有的安装组件和Docker镜像都放在goolge自己的网站上，这里的解决办法是从阿里云镜像仓库下载镜像，拉取到本地以后改回默认的镜像tag。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat &#60;&#60;EOF&#62; ./k8simage.sh&#10;#!/bin/bash&#10;images=(&#10;&#9;kube-apiserver:v1.17.4&#10;&#9;kube-controller-manager:v1.17.4&#10;&#9;kube-scheduler:v1.17.4&#10;&#9;kube-proxy:v1.17.4&#10;&#9;pause:3.1&#10;&#9;etcd:3.4.3-0&#10;&#9;coredns:1.6.5&#10;)&#10;for imageName in $&#123;images[@]&#125;;do&#10;&#9;docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName&#10;&#9;docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName&#10;&#9;docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName &#10;done&#10;EOF&#10;&#10;[root@master ~]# chmod 755 k8simage.sh&#10;[root@master ~]# ./k8simage.sh</span><br></pre></td></tr></table></figure>
<h4 id="集群验证"><a href="#集群验证" class="headerlink" title="集群验证"></a>集群验证</h4><h6 id="集群初始化"><a href="#集群初始化" class="headerlink" title="集群初始化"></a>集群初始化</h6><ol>
<li><p>master上操作</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubeadm init --apiserver-advertise-address=192.168.36.10 --kubernetes-version v1.17.4 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16  --image-repository registry.aliyuncs.com/google_containers&#10;W1013 10:37:33.958785    1872 validation.go:28] Cannot validate kube-proxy config - no validator is available&#10;W1013 10:37:33.958821    1872 validation.go:28] Cannot validate kubelet config - no validator is available&#10;[init] Using Kubernetes version: v1.17.4&#10;[preflight] Running pre-flight checks&#10;[preflight] Pulling images required for setting up a Kubernetes cluster&#10;[preflight] This might take a minute or two, depending on the speed of your internet connection&#10;[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;&#10;[kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;&#10;[kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;&#10;[kubelet-start] Starting the kubelet&#10;[certs] Using certificateDir folder &#34;/etc/kubernetes/pki&#34;&#10;[certs] Generating &#34;ca&#34; certificate and key&#10;[certs] Generating &#34;apiserver&#34; certificate and key&#10;[certs] apiserver serving cert is signed for DNS names [master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.36.10]&#10;[certs] Generating &#34;apiserver-kubelet-client&#34; certificate and key&#10;[certs] Generating &#34;front-proxy-ca&#34; certificate and key&#10;[certs] Generating &#34;front-proxy-client&#34; certificate and key&#10;[certs] Generating &#34;etcd/ca&#34; certificate and key&#10;[certs] Generating &#34;etcd/server&#34; certificate and key&#10;[certs] etcd/server serving cert is signed for DNS names [master localhost] and IPs [192.168.36.10 127.0.0.1 ::1]&#10;[certs] Generating &#34;etcd/peer&#34; certificate and key&#10;[certs] etcd/peer serving cert is signed for DNS names [master localhost] and IPs [192.168.36.10 127.0.0.1 ::1]&#10;[certs] Generating &#34;etcd/healthcheck-client&#34; certificate and key&#10;[certs] Generating &#34;apiserver-etcd-client&#34; certificate and key&#10;[certs] Generating &#34;sa&#34; key and public key&#10;[kubeconfig] Using kubeconfig folder &#34;/etc/kubernetes&#34;&#10;[kubeconfig] Writing &#34;admin.conf&#34; kubeconfig file&#10;[kubeconfig] Writing &#34;kubelet.conf&#34; kubeconfig file&#10;[kubeconfig] Writing &#34;controller-manager.conf&#34; kubeconfig file&#10;[kubeconfig] Writing &#34;scheduler.conf&#34; kubeconfig file&#10;[control-plane] Using manifest folder &#34;/etc/kubernetes/manifests&#34;&#10;[control-plane] Creating static Pod manifest for &#34;kube-apiserver&#34;&#10;[control-plane] Creating static Pod manifest for &#34;kube-controller-manager&#34;&#10;W1013 10:40:01.037622    1872 manifests.go:214] the default kube-apiserver authorization-mode is &#34;Node,RBAC&#34;; using &#34;Node,RBAC&#34;&#10;[control-plane] Creating static Pod manifest for &#34;kube-scheduler&#34;&#10;W1013 10:40:01.039721    1872 manifests.go:214] the default kube-apiserver authorization-mode is &#34;Node,RBAC&#34;; using &#34;Node,RBAC&#34;&#10;[etcd] Creating static Pod manifest for local etcd in &#34;/etc/kubernetes/manifests&#34;&#10;[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &#34;/etc/kubernetes/manifests&#34;. This can take up to 4m0s&#10;[apiclient] All control plane components are healthy after 20.522009 seconds&#10;[upload-config] Storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace&#10;[kubelet] Creating a ConfigMap &#34;kubelet-config-1.17&#34; in namespace kube-system with the configuration for the kubelets in the cluster&#10;[upload-certs] Skipping phase. Please see --upload-certs&#10;[mark-control-plane] Marking the node master as control-plane by adding the label &#34;node-role.kubernetes.io/master=&#39;&#39;&#34;&#10;[mark-control-plane] Marking the node master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]&#10;[bootstrap-token] Using token: 9ejhyb.0bbmx3l90b9xkd0j&#10;[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles&#10;[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials&#10;[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token&#10;[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster&#10;[bootstrap-token] Creating the &#34;cluster-info&#34; ConfigMap in the &#34;kube-public&#34; namespace&#10;[kubelet-finalize] Updating &#34;/etc/kubernetes/kubelet.conf&#34; to point to a rotatable kubelet client certificate and key&#10;[addons] Applied essential addon: CoreDNS&#10;[addons] Applied essential addon: kube-proxy&#10;&#10;Your Kubernetes control-plane has initialized successfully!&#10;&#10;To start using your cluster, you need to run the following as a regular user:&#10;&#10;  mkdir -p $HOME/.kube&#10;  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config&#10;  sudo chown $(id -u):$(id -g) $HOME/.kube/config&#10;&#10;You should now deploy a pod network to the cluster.&#10;Run &#34;kubectl apply -f [podnetwork].yaml&#34; with one of the options listed at:&#10;  https://kubernetes.io/docs/concepts/cluster-administration/addons/&#10;&#10;Then you can join any number of worker nodes by running the following on each as root:&#10;&#10;kubeadm join 192.168.36.10:6443 --token 9ejhyb.0bbmx3l90b9xkd0j \&#10;    --discovery-token-ca-cert-hash sha256:b206e4be9fbe0d49d8e7df1c9e783efc590471bbf5510ae79be5c3a6626748b4</span><br></pre></td></tr></table></figure>
</li>
<li><p>cluster配置</p>
<p>根据提示操作</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# mkdir -p $HOME/.kube&#10;[root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config&#10;[root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
</li>
<li><p>node上操作</p>
<p>根据上面的提示执行下面操作</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# kubeadm join 192.168.36.10:6443 --token 9ejhyb.0bbmx3l90b9xkd0j \&#10;&#62;     --discovery-token-ca-cert-hash sha256:b206e4be9fbe0d49d8e7df1c9e783efc590471bbf5510ae79be5c3a6626748b4&#10;W1013 10:56:24.205622    2554 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.&#10;[preflight] Running pre-flight checks&#10;[preflight] Reading configuration from the cluster...&#10;[preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;&#10;[kubelet-start] Downloading configuration for the kubelet from the &#34;kubelet-config-1.17&#34; ConfigMap in the kube-system namespace&#10;[kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;&#10;[kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;&#10;[kubelet-start] Starting the kubelet&#10;[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...&#10;&#10;This node has joined the cluster:&#10;* Certificate signing request was sent to apiserver and a response was received.&#10;* The Kubelet was informed of the new secure connection details.&#10;&#10;Run &#39;kubectl get nodes&#39; on the control-plane to see this node join the cluster.</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证nodes</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get nodes&#10;NAME     STATUS     ROLES    AGE    VERSION&#10;master   NotReady   master   22m    v1.17.4&#10;node1    NotReady   &#60;none&#62;   6m1s   v1.17.4&#10;node2    NotReady   &#60;none&#62;   6m8s   v1.17.4</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装网络插件</p>
<p>只在master操作</p>
<p>外网访问不了，直接把文件内容Copy进去</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml&#10;# https://github.com/flannel-io/flannel/tree/master/Documentation/kube-flannel.yml&#10;&#10;cat &#60;&#60;EOF&#62; ./kube-flannel.yml&#10;---&#10;apiVersion: policy/v1beta1&#10;kind: PodSecurityPolicy&#10;metadata:&#10;  name: psp.flannel.unprivileged&#10;  annotations:&#10;    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default&#10;    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default&#10;    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default&#10;    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default&#10;spec:&#10;  privileged: false&#10;  volumes:&#10;  - configMap&#10;  - secret&#10;  - emptyDir&#10;  - hostPath&#10;  allowedHostPaths:&#10;  - pathPrefix: &#34;/etc/cni/net.d&#34;&#10;  - pathPrefix: &#34;/etc/kube-flannel&#34;&#10;  - pathPrefix: &#34;/run/flannel&#34;&#10;  readOnlyRootFilesystem: false&#10;  # Users and groups&#10;  runAsUser:&#10;    rule: RunAsAny&#10;  supplementalGroups:&#10;    rule: RunAsAny&#10;  fsGroup:&#10;    rule: RunAsAny&#10;  # Privilege Escalation&#10;  allowPrivilegeEscalation: false&#10;  defaultAllowPrivilegeEscalation: false&#10;  # Capabilities&#10;  allowedCapabilities: [&#39;NET_ADMIN&#39;, &#39;NET_RAW&#39;]&#10;  defaultAddCapabilities: []&#10;  requiredDropCapabilities: []&#10;  # Host namespaces&#10;  hostPID: false&#10;  hostIPC: false&#10;  hostNetwork: true&#10;  hostPorts:&#10;  - min: 0&#10;    max: 65535&#10;  # SELinux&#10;  seLinux:&#10;    # SELinux is unused in CaaSP&#10;    rule: &#39;RunAsAny&#39;&#10;---&#10;kind: ClusterRole&#10;apiVersion: rbac.authorization.k8s.io/v1&#10;metadata:&#10;  name: flannel&#10;rules:&#10;- apiGroups: [&#39;extensions&#39;]&#10;  resources: [&#39;podsecuritypolicies&#39;]&#10;  verbs: [&#39;use&#39;]&#10;  resourceNames: [&#39;psp.flannel.unprivileged&#39;]&#10;- apiGroups:&#10;  - &#34;&#34;&#10;  resources:&#10;  - pods&#10;  verbs:&#10;  - get&#10;- apiGroups:&#10;  - &#34;&#34;&#10;  resources:&#10;  - nodes&#10;  verbs:&#10;  - list&#10;  - watch&#10;- apiGroups:&#10;  - &#34;&#34;&#10;  resources:&#10;  - nodes/status&#10;  verbs:&#10;  - patch&#10;---&#10;kind: ClusterRoleBinding&#10;apiVersion: rbac.authorization.k8s.io/v1&#10;metadata:&#10;  name: flannel&#10;roleRef:&#10;  apiGroup: rbac.authorization.k8s.io&#10;  kind: ClusterRole&#10;  name: flannel&#10;subjects:&#10;- kind: ServiceAccount&#10;  name: flannel&#10;  namespace: kube-system&#10;---&#10;apiVersion: v1&#10;kind: ServiceAccount&#10;metadata:&#10;  name: flannel&#10;  namespace: kube-system&#10;---&#10;kind: ConfigMap&#10;apiVersion: v1&#10;metadata:&#10;  name: kube-flannel-cfg&#10;  namespace: kube-system&#10;  labels:&#10;    tier: node&#10;    app: flannel&#10;data:&#10;  cni-conf.json: |&#10;    &#123;&#10;      &#34;name&#34;: &#34;cbr0&#34;,&#10;      &#34;cniVersion&#34;: &#34;0.3.1&#34;,&#10;      &#34;plugins&#34;: [&#10;        &#123;&#10;          &#34;type&#34;: &#34;flannel&#34;,&#10;          &#34;delegate&#34;: &#123;&#10;            &#34;hairpinMode&#34;: true,&#10;            &#34;isDefaultGateway&#34;: true&#10;          &#125;&#10;        &#125;,&#10;        &#123;&#10;          &#34;type&#34;: &#34;portmap&#34;,&#10;          &#34;capabilities&#34;: &#123;&#10;            &#34;portMappings&#34;: true&#10;          &#125;&#10;        &#125;&#10;      ]&#10;    &#125;&#10;  net-conf.json: |&#10;    &#123;&#10;      &#34;Network&#34;: &#34;10.244.0.0/16&#34;,&#10;      &#34;Backend&#34;: &#123;&#10;        &#34;Type&#34;: &#34;vxlan&#34;&#10;      &#125;&#10;    &#125;&#10;---&#10;apiVersion: apps/v1&#10;kind: DaemonSet&#10;metadata:&#10;  name: kube-flannel-ds&#10;  namespace: kube-system&#10;  labels:&#10;    tier: node&#10;    app: flannel&#10;spec:&#10;  selector:&#10;    matchLabels:&#10;      app: flannel&#10;  template:&#10;    metadata:&#10;      labels:&#10;        tier: node&#10;        app: flannel&#10;    spec:&#10;      affinity:&#10;        nodeAffinity:&#10;          requiredDuringSchedulingIgnoredDuringExecution:&#10;            nodeSelectorTerms:&#10;            - matchExpressions:&#10;              - key: kubernetes.io/os&#10;                operator: In&#10;                values:&#10;                - linux&#10;      hostNetwork: true&#10;      priorityClassName: system-node-critical&#10;      tolerations:&#10;      - operator: Exists&#10;        effect: NoSchedule&#10;      serviceAccountName: flannel&#10;      initContainers:&#10;      - name: install-cni&#10;        image: quay.io/coreos/flannel:v0.14.0&#10;        command:&#10;        - cp&#10;        args:&#10;        - -f&#10;        - /etc/kube-flannel/cni-conf.json&#10;        - /etc/cni/net.d/10-flannel.conflist&#10;        volumeMounts:&#10;        - name: cni&#10;          mountPath: /etc/cni/net.d&#10;        - name: flannel-cfg&#10;          mountPath: /etc/kube-flannel/&#10;      containers:&#10;      - name: kube-flannel&#10;        image: quay.io/coreos/flannel:v0.14.0&#10;        command:&#10;        - /opt/bin/flanneld&#10;        args:&#10;        - --ip-masq&#10;        - --kube-subnet-mgr&#10;        resources:&#10;          requests:&#10;            cpu: &#34;100m&#34;&#10;            memory: &#34;50Mi&#34;&#10;          limits:&#10;            cpu: &#34;100m&#34;&#10;            memory: &#34;50Mi&#34;&#10;        securityContext:&#10;          privileged: false&#10;          capabilities:&#10;            add: [&#34;NET_ADMIN&#34;, &#34;NET_RAW&#34;]&#10;        env:&#10;        - name: POD_NAME&#10;          valueFrom:&#10;            fieldRef:&#10;              fieldPath: metadata.name&#10;        - name: POD_NAMESPACE&#10;          valueFrom:&#10;            fieldRef:&#10;              fieldPath: metadata.namespace&#10;        volumeMounts:&#10;        - name: run&#10;          mountPath: /run/flannel&#10;        - name: flannel-cfg&#10;          mountPath: /etc/kube-flannel/&#10;      volumes:&#10;      - name: run&#10;        hostPath:&#10;          path: /run/flannel&#10;      - name: cni&#10;        hostPath:&#10;          path: /etc/cni/net.d&#10;      - name: flannel-cfg&#10;        configMap:&#10;          name: kube-flannel-cfg&#10;EOF</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f kube-flannel.yml &#10;podsecuritypolicy.policy/psp.flannel.unprivileged created&#10;clusterrole.rbac.authorization.k8s.io/flannel created&#10;clusterrolebinding.rbac.authorization.k8s.io/flannel created&#10;serviceaccount/flannel created&#10;configmap/kube-flannel-cfg created&#10;daemonset.apps/kube-flannel-ds created</span><br></pre></td></tr></table></figure>
</li>
<li><p>等待它安装完毕 发现已经是 集群的状态已经是Ready</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get nodes&#10;NAME     STATUS   ROLES    AGE   VERSION&#10;master   Ready    master   29m   v1.17.4&#10;node1    Ready    &#60;none&#62;   13m   v1.17.4&#10;node2    Ready    &#60;none&#62;   13m   v1.17.4</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h6 id="集群测试"><a href="#集群测试" class="headerlink" title="集群测试"></a>集群测试</h6><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># &#21019;&#24314;&#19968;&#20010;Nginx&#26381;&#21153;&#10;[root@master ~]# kubectl create deployment nginx  --image=nginx:1.14-alpine&#10;deployment.apps/nginx created&#10;# &#26292;&#38706;&#31471;&#21475;&#10;[root@master ~]# kubectl expose deploy nginx  --port=80 --target-port=80  --type=NodePort&#10;service/nginx exposed</span><br></pre></td></tr></table></figure>
<p>验证：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# curl master:32020&#10;&#60;!DOCTYPE html&#62;&#10;&#60;html&#62;&#10;&#60;head&#62;&#10;&#60;title&#62;Welcome to nginx!&#60;/title&#62;&#10;&#60;style&#62;&#10;    body &#123;&#10;        width: 35em;&#10;        margin: 0 auto;&#10;        font-family: Tahoma, Verdana, Arial, sans-serif;&#10;    &#125;&#10;&#60;/style&#62;&#10;&#60;/head&#62;&#10;&#60;body&#62;&#10;&#60;h1&#62;Welcome to nginx!&#60;/h1&#62;&#10;&#60;p&#62;If you see this page, the nginx web server is successfully installed and&#10;working. Further configuration is required.&#60;/p&#62;&#10;&#10;&#60;p&#62;For online documentation and support please refer to&#10;&#60;a href=&#34;http://nginx.org/&#34;&#62;nginx.org&#60;/a&#62;.&#60;br/&#62;&#10;Commercial support is available at&#10;&#60;a href=&#34;http://nginx.com/&#34;&#62;nginx.com&#60;/a&#62;.&#60;/p&#62;&#10;&#10;&#60;p&#62;&#60;em&#62;Thank you for using nginx.&#60;/em&#62;&#60;/p&#62;&#10;&#60;/body&#62;&#10;&#60;/html&#62;&#10;[root@master ~]# curl node1:32020&#10;&#60;!DOCTYPE html&#62;&#10;&#60;html&#62;&#10;&#60;head&#62;&#10;&#60;title&#62;Welcome to nginx!&#60;/title&#62;&#10;&#60;style&#62;&#10;    body &#123;&#10;        width: 35em;&#10;        margin: 0 auto;&#10;        font-family: Tahoma, Verdana, Arial, sans-serif;&#10;    &#125;&#10;&#60;/style&#62;&#10;&#60;/head&#62;&#10;&#60;body&#62;&#10;&#60;h1&#62;Welcome to nginx!&#60;/h1&#62;&#10;&#60;p&#62;If you see this page, the nginx web server is successfully installed and&#10;working. Further configuration is required.&#60;/p&#62;&#10;&#10;&#60;p&#62;For online documentation and support please refer to&#10;&#60;a href=&#34;http://nginx.org/&#34;&#62;nginx.org&#60;/a&#62;.&#60;br/&#62;&#10;Commercial support is available at&#10;&#60;a href=&#34;http://nginx.com/&#34;&#62;nginx.com&#60;/a&#62;.&#60;/p&#62;&#10;&#10;&#60;p&#62;&#60;em&#62;Thank you for using nginx.&#60;/em&#62;&#60;/p&#62;&#10;&#60;/body&#62;&#10;&#60;/html&#62;&#10;[root@master ~]# curl node2:32020&#10;&#60;!DOCTYPE html&#62;&#10;&#60;html&#62;&#10;&#60;head&#62;&#10;&#60;title&#62;Welcome to nginx!&#60;/title&#62;&#10;&#60;style&#62;&#10;    body &#123;&#10;        width: 35em;&#10;        margin: 0 auto;&#10;        font-family: Tahoma, Verdana, Arial, sans-serif;&#10;    &#125;&#10;&#60;/style&#62;&#10;&#60;/head&#62;&#10;&#60;body&#62;&#10;&#60;h1&#62;Welcome to nginx!&#60;/h1&#62;&#10;&#60;p&#62;If you see this page, the nginx web server is successfully installed and&#10;working. Further configuration is required.&#60;/p&#62;&#10;&#10;&#60;p&#62;For online documentation and support please refer to&#10;&#60;a href=&#34;http://nginx.org/&#34;&#62;nginx.org&#60;/a&#62;.&#60;br/&#62;&#10;Commercial support is available at&#10;&#60;a href=&#34;http://nginx.com/&#34;&#62;nginx.com&#60;/a&#62;.&#60;/p&#62;&#10;&#10;&#60;p&#62;&#60;em&#62;Thank you for using nginx.&#60;/em&#62;&#60;/p&#62;&#10;&#60;/body&#62;&#10;&#60;/html&#62;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/05/13/K8s入门介绍/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/13/K8s入门介绍/" itemprop="url">K8s：入门介绍</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-05-13T13:23:33+08:00">
                2021-05-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/05/13/K8s入门介绍/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/05/13/K8s入门介绍/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>kubernetes的本质是<strong>一组服务器集群</strong>，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：</p>
<ul>
<li><strong>自我修复</strong>：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器</li>
<li><strong>弹性伸缩</strong>：可以根据需要，自动对集群中正在运行的容器数量进行调整</li>
<li><strong>服务发现</strong>：服务可以通过自动发现的形式找到它所依赖的服务</li>
<li><strong>负载均衡</strong>：如果一个服务起动了多个容器，能够自动实现请求的负载均衡</li>
<li><strong>版本回退</strong>：如果发现新发布的程序版本有问题，可以立即回退到原来的版本</li>
<li><strong>存储编排</strong>：可以根据容器自身的需求自动创建存储卷</li>
</ul>
<h4 id="kubernetes组件"><a href="#kubernetes组件" class="headerlink" title="kubernetes组件"></a>kubernetes组件</h4><p>一个kubernetes集群主要是由<strong>控制节点(master)</strong>、<strong>工作节点(node)</strong>构成，每个节点上都会安装不同的组件。</p>
<p><img src="/images/k8s/arch.jpg" alt=""></p>
<p><strong>master：集群的控制平面，负责集群的决策 ( 管理 )</strong></p>
<blockquote>
<p><strong>ApiServer</strong> : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制</p>
<p><strong>Scheduler</strong> : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上</p>
<p><strong>ControllerManager</strong> : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等</p>
<p><strong>Etcd</strong> ：负责存储集群中各种资源对象的信息</p>
</blockquote>
<p><strong>node：集群的数据平面，负责为容器提供运行环境 ( 干活 )</strong></p>
<blockquote>
<p><strong>Kubelet</strong> : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器</p>
<p><strong>KubeProxy</strong> : 负责提供集群内部的服务发现和负载均衡</p>
<p><strong>Docker</strong> : 负责节点上容器的各种操作</p>
</blockquote>
<h4 id="kubernetes常用概念"><a href="#kubernetes常用概念" class="headerlink" title="kubernetes常用概念"></a>kubernetes常用概念</h4><p><strong>Master</strong>：集群控制节点，每个集群需要至少一个master节点负责集群的管控</p>
<p><strong>Node</strong>：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行</p>
<p><strong>Pod</strong>：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器</p>
<p><strong>Controller</strong>：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等</p>
<p><strong>Service</strong>：pod对外服务的统一入口，下面可以维护者同一类的多个pod</p>
<p><strong>Label</strong>：标签，用于对pod进行分类，同一类pod会拥有相同的标签</p>
<p><strong>NameSpace</strong>：命名空间，用来隔离pod的运行环境</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/04/14/Jmeter-JSR223使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/04/14/Jmeter-JSR223使用/" itemprop="url">Jmeter: JSR223使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-04-14T08:46:44+08:00">
                2021-04-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Jmeter/" itemprop="url" rel="index">
                    <span itemprop="name">Jmeter</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/04/14/Jmeter-JSR223使用/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/04/14/Jmeter-JSR223使用/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Jmeter经常用BeanShell来实现一些其本身不能处理的任务，但是BeanShell的效率不高，现在可以用JSR223来代替，支持groovy脚本，效率更高。</p>
<h4 id="常用内置变量"><a href="#常用内置变量" class="headerlink" title="常用内置变量"></a>常用内置变量</h4><ul>
<li><p><strong>Vars</strong> </p>
<p>定义变量与调用变量</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vars.<span class="built_in">get</span>(<span class="keyword">String</span> <span class="variable">key</span>)：从jmeter中获得变量值</span><br><span class="line"></span><br><span class="line">vars.put(<span class="keyword">String</span> <span class="variable">key</span>，<span class="keyword">String</span> value)：数据存到jmeter变量中</span><br><span class="line"></span><br><span class="line">vars.putObject(<span class="string">"OBJ1"</span>,<span class="keyword">new</span> <span class="keyword">Object</span>());</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Props</strong> </p>
<p>设置属性与调用属性</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$&#123;__setProperty(test1,property1,)&#125;</span>;</span><br><span class="line">props.put(“<span class="built_in">test</span>2”,“property2”);</span><br><span class="line">String <span class="built_in">test</span>1 =props.get(“<span class="built_in">test</span>1”);</span><br><span class="line">String <span class="built_in">test</span>2 = props.get(“<span class="built_in">test</span>2”);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Ctx</strong></p>
<p>通过它来访问当前线程的上下文</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">getVariables</span><span class="params">()</span></span>：获取当前线程的所有变量</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">getPreviousResult</span><span class="params">()</span></span> ：获取前一个取样器的结果</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>prev</strong></p>
<p>获取前面的sample采样的结果</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">getResponseDataAsString</span><span class="params">()</span></span>：获取响应信息</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">getResponseCode</span><span class="params">()</span></span> ：获取响应code</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>log</strong></p>
<p>打印日志 ，日志会保存在jmeter.log中</p>
</li>
</ul>
<h4 id="运行外部文件"><a href="#运行外部文件" class="headerlink" title="运行外部文件"></a>运行外部文件</h4><ul>
<li><p>Java</p>
<p>在JSR223中引入源文件并执行，执行与JAVA本身的方法一致</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source(“<span class="string">F:</span><span class="regexp">/Test/</span>demo1.java”);</span><br></pre></td></tr></table></figure>
</li>
<li><p>Jar</p>
<p>有下边两种方法可以引入jar包，执行与JAVA本身的方法一致<br>1、将jar包放到Jmeter安装目录的\lib\ext目录下<br>2、在测试计划中导入</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://izheyi.com/2021/04/02/Jmeter-常用设置in-properties/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐胡璐">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YONGFEIUALL">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/04/02/Jmeter-常用设置in-properties/" itemprop="url">Jmeter: 常用设置in properties</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-04-02T14:18:15+08:00">
                2021-04-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Jmeter/" itemprop="url" rel="index">
                    <span itemprop="name">Jmeter</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/04/02/Jmeter-常用设置in-properties/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2021/04/02/Jmeter-常用设置in-properties/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在Jmeter里常用的设置：</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">jmeter.hidpi.mode=<span class="keyword">true</span></span><br><span class="line">jmeter.hidpi.<span class="built_in">scale</span>.factor=<span class="number">2.0</span></span><br><span class="line">sampleresult.<span class="keyword">default</span>.encoding=UTF-<span class="number">8</span></span><br><span class="line">jsyntaxtextarea.font.<span class="built_in">size</span>=<span class="number">20</span></span><br><span class="line"></span><br><span class="line">jmeter.reportgenerator.overall_granularity=<span class="number">1000</span></span><br><span class="line"></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.bytes = <span class="keyword">true</span></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.label = <span class="keyword">true</span></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.latency = <span class="keyword">true</span></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.response_code = <span class="keyword">true</span></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.response_message = <span class="keyword">true</span></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.successful = <span class="keyword">true</span></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.thread_counts = <span class="keyword">true</span></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.thread_name = <span class="keyword">true</span></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.time = <span class="keyword">true</span></span><br><span class="line"># the timestamp format must include the time and should include the date.</span><br><span class="line"># For example the <span class="keyword">default</span>, which is milliseconds since the epoch: </span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.timestamp_format = ms</span><br><span class="line"># Or the following would also be suitable</span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.timestamp_format = yyyy/MM/dd HH:mm:ss</span><br><span class="line"></span><br><span class="line">jmeter.<span class="built_in">save</span>.saveservice.assertion_results_failure_message = <span class="keyword">true</span></span><br></pre></td></tr></table></figure>
<p>建议在user.properties里设置。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/40/">40</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="唐胡璐" />
            
              <p class="site-author-name" itemprop="name">唐胡璐</p>
              <p class="site-description motion-element" itemprop="description">i just wanna live while i am alive</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">391</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">74</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://www.linkedin.com/in/yongfeiuall" target="_blank" title="LinkedIn">
                      
                        <i class="fa fa-fw fa-linkedin"></i>LinkedIn</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://weibo.com/yongfeiuall" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yongfeiuall" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="yongfeiuall@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          
            <div class="cc-license motion-element" itemprop="license">
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
                <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
              </a>
            </div>
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">唐胡璐</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	

		<script type="text/javascript">
		_hcwp = window._hcwp || [];

		_hcwp.push({widget:"Bloggerstream", widget_id: 101212, selector:".hc-comment-count", label: "{\%COUNT%\}" });

		

		(function() {
		if("HC_LOAD_INIT" in window)return;
		HC_LOAD_INIT = true;
		var lang = (navigator.language || navigator.systemLanguage || navigator.userLanguage || "en").substr(0, 2).toLowerCase();
		var hcc = document.createElement("script"); hcc.type = "text/javascript"; hcc.async = true;
		hcc.src = ("https:" == document.location.protocol ? "https" : "http")+"://w.hypercomments.com/widget/hc/101212/"+lang+"/widget.js";
		var s = document.getElementsByTagName("script")[0];
		s.parentNode.insertBefore(hcc, s.nextSibling);
		})();
		</script>

	
















  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "default";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Wechat,Linkedin,Weibo,Mailto,Douban,QQZone,Twitter,Reddit,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  

  

  

</body>
</html>
